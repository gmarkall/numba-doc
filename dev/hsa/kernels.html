<!DOCTYPE html>




<html lang="en">
  <head>
    <meta charset="utf-8" />
    
    <title>5.2. Writing HSA Kernels &mdash; Numba 0.21.0+242.gf3c4657-py2.7-linux-x86_64.egg documentation</title>

    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">
    <meta name="author" content="">

    
<link rel="stylesheet" href="../_static/css/basicstrap-base.css" type="text/css" />
<link rel="stylesheet" href="../_static/css/bootstrap.min.css" type="text/css" />
<link rel="stylesheet" href="../_static/css/font-awesome.min.css">
<!--[if IE 7]>
<link rel="stylesheet" href="../_static/css/font-awesome-ie7.min.css">
<![endif]-->
<style type="text/css">
  body {
    padding-top: 60px;
    padding-bottom: 40px;
  }
}
</style>
<link rel="stylesheet" href="../_static/basicstrap.css" type="text/css" />
<link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
<link rel="stylesheet" href="../_static/css/bootstrap-responsive.min.css" type="text/css" />
    
<script type="text/javascript">
  var DOCUMENTATION_OPTIONS = {
            URL_ROOT:    '../',
            VERSION:     '0.21.0+242.gf3c4657-py2.7-linux-x86_64.egg',
            COLLAPSE_INDEX: false,
            FILE_SUFFIX: '.html',
            HAS_SOURCE:  true
  };
</script>
<script type="text/javascript" src="../_static/js/jquery.min.js"></script>
<script type="text/javascript" src="../_static/underscore.js"></script>
<script type="text/javascript" src="../_static/doctools.js"></script>
<script type="text/javascript" src="../_static/js/bootstrap.min.js"></script>
<script type="text/javascript">
  $(document).ready(function(){
    $('.show-sidebar').click(function(e) {
       e.preventDefault();
       if ($(".show-sidebar").html() == "Open Table Of Contents") {
          $('.for-mobile').removeClass('hidden-phone');
          $(".show-sidebar").html("Close Table Of Contents");
       } else {
          $(".show-sidebar").html("Open Table Of Contents");
       }
    });
  });
</script>
    <link rel="top" title="Numba 0.21.0+242.gf3c4657-py2.7-linux-x86_64.egg documentation" href="../index.html" />
    <link rel="up" title="5. Numba for HSA APUs" href="index.html" />
    <link rel="next" title="5.3. Memory management" href="memory.html" />
    <link rel="prev" title="5.1. Overview" href="overview.html" /> 
  </head>
  <body>
    <div class="navbar navbar-fixed-top ">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="../index.html">Numba 0.21.0+242.gf3c4657-py2.7-linux-x86_64.egg documentation</a>
          <div class="nav-collapse collapse">
            <ul class="nav pull-right">
              
                <li>
                <a href="../genindex.html" title="General Index" accesskey="I">index</a>
                </li>
                <li>
                <a href="memory.html" title="5.3. Memory management" accesskey="N">next</a>
                </li>
                <li>
                <a href="overview.html" title="5.1. Overview" accesskey="P">previous</a>
                </li>
                <li>
                <a href="index.html" accesskey="U">5. Numba for HSA APUs</a>
                </li>
              
            </ul>
          </div>
        </div>
      </div>
    </div>
    

    <!-- container -->
    <div class="container-fluid">


      
      <div class="row-fluid hidden-desktop hidden-tablet">
      
<div class="span3 ">
  <a class="visible-phone btn btn-small show-sidebar" data-toggle="collapse" data-target=".for-mobile">Open Table Of Contents</a>
  <div class="for-mobile sidebar hidden-phone">
  <h3><a href="../index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">5.2. Writing HSA Kernels</a><ul>
<li><a class="reference internal" href="#introduction">5.2.1. Introduction</a></li>
<li><a class="reference internal" href="#introduction-for-cuda-programmers">5.2.2. Introduction for CUDA Programmers</a></li>
<li><a class="reference internal" href="#kernel-declaration">5.2.3. Kernel declaration</a></li>
<li><a class="reference internal" href="#kernel-invocation">5.2.4. Kernel invocation</a><ul>
<li><a class="reference internal" href="#choosing-the-workgroup-size">5.2.4.1. Choosing the workgroup size</a></li>
<li><a class="reference internal" href="#multi-dimensional-workgroup-and-ndrange">5.2.4.2. Multi-dimensional workgroup and ndrange</a></li>
</ul>
</li>
<li><a class="reference internal" href="#workitem-positioning">5.2.5. WorkItem positioning</a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="overview.html"
                        title="previous chapter">5.1. Overview</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="memory.html"
                        title="next chapter">5.3. Memory management</a></p>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../_sources/hsa/kernels.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox">
  <h3>Quick search</h3>
  <form class="search form-search" action="../search.html" method="get">
      <div class="input-append">
        <input type="text" class="search-query" name="q">
        <input type="submit" class="btn" value="Go" />
      </div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
  </div>
</div>
      </div>
      

      <!-- row -->
      <div class="row-fluid">
         
<div class="span3 visible-desktop visible-tablet">
  <div class=" sidebar hidden-phone">
  <h3><a href="../index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">5.2. Writing HSA Kernels</a><ul>
<li><a class="reference internal" href="#introduction">5.2.1. Introduction</a></li>
<li><a class="reference internal" href="#introduction-for-cuda-programmers">5.2.2. Introduction for CUDA Programmers</a></li>
<li><a class="reference internal" href="#kernel-declaration">5.2.3. Kernel declaration</a></li>
<li><a class="reference internal" href="#kernel-invocation">5.2.4. Kernel invocation</a><ul>
<li><a class="reference internal" href="#choosing-the-workgroup-size">5.2.4.1. Choosing the workgroup size</a></li>
<li><a class="reference internal" href="#multi-dimensional-workgroup-and-ndrange">5.2.4.2. Multi-dimensional workgroup and ndrange</a></li>
</ul>
</li>
<li><a class="reference internal" href="#workitem-positioning">5.2.5. WorkItem positioning</a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="overview.html"
                        title="previous chapter">5.1. Overview</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="memory.html"
                        title="next chapter">5.3. Memory management</a></p>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../_sources/hsa/kernels.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox">
  <h3>Quick search</h3>
  <form class="search form-search" action="../search.html" method="get">
      <div class="input-append">
        <input type="text" class="search-query" name="q">
        <input type="submit" class="btn" value="Go" />
      </div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
  </div>
</div> 
        

        <div class="span9">
          <div class="document">
            <div class="documentwrapper">
              <div class="bodywrapper">
                <div class="body">
                  
  <div class="section" id="writing-hsa-kernels">
<h1>5.2. Writing HSA Kernels<a class="headerlink" href="#writing-hsa-kernels" title="Permalink to this headline">¶</a></h1>
<div class="section" id="introduction">
<h2>5.2.1. Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h2>
<p>HSA provides an execution model similar to OpenCL.  Instructions are executed
in parallel by a group of hardware threads.  In some way, this is similar to
<em>single-instruction-multiple-data</em> (SIMD) model but with the convenience that
the fine-grain scheduling is hidden from the programmer instead of programming
with SIMD vectors as a data structure.  In HSA, the code you write will be
executed by multiple threads at once (often hundreds or thousands).  Your
solution will
be modeled by defining a thread hierarchy of <em>NDRange</em>, <em>workgroup</em> and
<em>workitem</em>.</p>
<p>Numba&#8217;s HSA support exposes facilities to declare and manage this
hierarchy of threads.</p>
</div>
<div class="section" id="introduction-for-cuda-programmers">
<h2>5.2.2. Introduction for CUDA Programmers<a class="headerlink" href="#introduction-for-cuda-programmers" title="Permalink to this headline">¶</a></h2>
<p>HSA execution model is similar to CUDA.  The main difference will be the
shared memory model employed by HSA so that there are no device memory.  The
GPU hardware uses the machine&#8217;s main memory (or host memory in
CUDA term) directly.  Therefore, you will not need <code class="docutils literal"><span class="pre">to_device()</span></code> and
<code class="docutils literal"><span class="pre">copy_to_host()</span></code> in HSA programming.</p>
<p>Here&#8217;s a quick mapping of the CUDA terms to HSA (opencl terms):
* workitem is CUDA threads
* workgroup is CUDA thread block
* NDrange is CUDA grid</p>
</div>
<div class="section" id="kernel-declaration">
<h2>5.2.3. Kernel declaration<a class="headerlink" href="#kernel-declaration" title="Permalink to this headline">¶</a></h2>
<p>A <em>kernel function</em> is a GPU function that is meant to be called from CPU
code.  It gives it two fundamental characteristics:</p>
<ul class="simple">
<li>kernels cannot explicitly return a value; all result data must be written
to an array passed to the function (if computing a scalar, you will
probably pass a one-element array);</li>
<li>kernels explicitly declare their thread hierarchy when called: i.e.
the number of workgroups and the number of workitems per workgroup
(note that while a kernel is compiled once, it can be called multiple
times with different workgroup sizes or NDrange sizes).</li>
</ul>
<p>At first sight, writing a HSA kernel with Numba looks very much like
writing a <a class="reference internal" href="../glossary.html#term-jit-function"><span class="xref std std-term">JIT function</span></a> for the CPU:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="nd">@hsa.jit</span>
<span class="k">def</span> <span class="nf">increment_by_one</span><span class="p">(</span><span class="n">an_array</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Increment all array elements by one.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c"># code elided here; read further for different implementations</span>
</pre></div>
</div>
</div>
<div class="section" id="kernel-invocation">
<span id="hsa-kernel-invocation"></span><h2>5.2.4. Kernel invocation<a class="headerlink" href="#kernel-invocation" title="Permalink to this headline">¶</a></h2>
<p>A kernel is typically launched in the following way:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">itempergroup</span> <span class="o">=</span> <span class="mi">32</span>
<span class="n">groupperrange</span> <span class="o">=</span> <span class="p">(</span><span class="n">an_array</span><span class="o">.</span><span class="n">size</span> <span class="o">+</span> <span class="p">(</span><span class="n">itempergroup</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span> <span class="o">//</span> <span class="n">itempergroup</span>
<span class="n">increment_by_one</span><span class="p">[</span><span class="n">groupperrange</span><span class="p">,</span> <span class="n">itempergroup</span><span class="p">](</span><span class="n">an_array</span><span class="p">)</span>
</pre></div>
</div>
<p>We notice two steps here:</p>
<ul class="simple">
<li>Instantiate the kernel proper, by specifying a number of workgroup
(or &#8220;workgroup per ndrange&#8221;), and a number of workitems per workgroup.  The
product of the two will give the total number of workitem launched.  Kernel
instantiation is done by taking the compiled kernel function
(here <code class="docutils literal"><span class="pre">increment_by_one</span></code>) and indexing it with a tuple of integers.</li>
<li>Running the kernel, by passing it the input array (and any separate
output arrays if necessary).  By default, running a kernel is synchronous:
the function returns when the kernel has finished executing and the
data is synchronized back.</li>
</ul>
<div class="section" id="choosing-the-workgroup-size">
<h3>5.2.4.1. Choosing the workgroup size<a class="headerlink" href="#choosing-the-workgroup-size" title="Permalink to this headline">¶</a></h3>
<p>It might seem curious to have a two-level hierarchy when declaring the
number of workitem needed by a kernel.  The workgroup size (i.e. number of
workitem per workgroup) is often crucial:</p>
<ul>
<li><p class="first">On the software side, the workgroup size determines how many threads
share a given area of <a class="reference internal" href="memory.html#hsa-shared-memory"><span>shared memory</span></a>.</p>
</li>
<li><dl class="first docutils">
<dt>On the hardware side, the workgroup size must be large enough for full</dt>
<dd><p class="first last">occupation of execution units.</p>
</dd>
</dl>
</li>
</ul>
</div>
<div class="section" id="multi-dimensional-workgroup-and-ndrange">
<h3>5.2.4.2. Multi-dimensional workgroup and ndrange<a class="headerlink" href="#multi-dimensional-workgroup-and-ndrange" title="Permalink to this headline">¶</a></h3>
<p>To help deal with multi-dimensional arrays, HSA allows you to specify
multi-dimensional workgroups and ndranges.  In the example above, you could
make <code class="docutils literal"><span class="pre">itempergroup</span></code> and <code class="docutils literal"><span class="pre">groupperrange</span></code> tuples of one, two
or three integers.  Compared to 1D declarations of equivalent sizes,
this doesn&#8217;t change anything to the efficiency or behaviour of generated
code, but can help you write your algorithms in a more natural way.</p>
</div>
</div>
<div class="section" id="workitem-positioning">
<h2>5.2.5. WorkItem positioning<a class="headerlink" href="#workitem-positioning" title="Permalink to this headline">¶</a></h2>
<p>When running a kernel, the kernel function&#8217;s code is executed by every
thread once.  It therefore has to know which thread it is in, in order
to know which array element(s) it is responsible for (complex algorithms
may define more complex responsibilities, but the underlying principle
is the same).</p>
<p>One way is for the thread to determines its position in the ndrange and
workgroup and manually compute the corresponding array position:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="nd">@hsa.jit</span>
<span class="k">def</span> <span class="nf">increment_by_one</span><span class="p">(</span><span class="n">an_array</span><span class="p">):</span>
    <span class="c"># workitem id in a 1D workgroup</span>
    <span class="n">tx</span> <span class="o">=</span> <span class="n">hsa</span><span class="o">.</span><span class="n">get_local_id</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="c"># workgroup id in a 1D ndrange</span>
    <span class="n">ty</span> <span class="o">=</span> <span class="n">hsa</span><span class="o">.</span><span class="n">get_group_id</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="c"># workgroup size, i.e. number of workitem per workgroup</span>
    <span class="n">bw</span> <span class="o">=</span> <span class="n">hsa</span><span class="o">.</span><span class="n">get_local_size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="c"># Compute flattened index inside the array</span>
    <span class="n">pos</span> <span class="o">=</span> <span class="n">tx</span> <span class="o">+</span> <span class="n">ty</span> <span class="o">*</span> <span class="n">bw</span>
    <span class="c"># The above is equivalent to pos = hsa.get_global_id(0)</span>
    <span class="k">if</span> <span class="n">pos</span> <span class="o">&lt;</span> <span class="n">an_array</span><span class="o">.</span><span class="n">size</span><span class="p">:</span>  <span class="c"># Check array boundaries</span>
        <span class="n">an_array</span><span class="p">[</span><span class="n">pos</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">1</span>
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Unless you are sure the workgroup size and grid size is a divisor
of your array size, you <strong>must</strong> check boundaries as shown above.</p>
</div>
<p><a class="reference internal" href="#numba.hsa.get_local_id" title="numba.hsa.get_local_id"><code class="xref py py-func docutils literal"><span class="pre">get_local_id()</span></code></a>, <a class="reference internal" href="#numba.hsa.get_local_size" title="numba.hsa.get_local_size"><code class="xref py py-func docutils literal"><span class="pre">get_local_size()</span></code></a>, <a class="reference internal" href="#numba.hsa.get_group_id" title="numba.hsa.get_group_id"><code class="xref py py-func docutils literal"><span class="pre">get_group_id()</span></code></a> and
<a class="reference internal" href="#numba.hsa.get_global_id" title="numba.hsa.get_global_id"><code class="xref py py-func docutils literal"><span class="pre">get_global_id()</span></code></a> are special functions provided by the HSA backend for
the sole purpose of knowing the geometry of the thread hierarchy and the
position of the current workitem within that geometry.</p>
<dl class="function">
<dt id="numba.hsa.get_local_id">
<code class="descclassname">numba.hsa.</code><code class="descname">get_local_id</code><span class="sig-paren">(</span><em>dim</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.hsa.get_local_id" title="Permalink to this definition">¶</a></dt>
<dd><p>Takes the index of the dimension being queried</p>
<p>Returns local workitem ID in the the current workgroup for the given
dimension. For 1D workgroup, the index is an integer spanning the range
from 0 inclusive to <a class="reference internal" href="#numba.hsa.get_local_size" title="numba.hsa.get_local_size"><code class="xref py py-func docutils literal"><span class="pre">numba.hsa.get_local_size()</span></code></a> exclusive.</p>
</dd></dl>

<dl class="function">
<dt id="numba.hsa.get_local_size">
<code class="descclassname">numba.hsa.</code><code class="descname">get_local_size</code><span class="sig-paren">(</span><em>dim</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.hsa.get_local_size" title="Permalink to this definition">¶</a></dt>
<dd><p>Takes the index of the dimension being queried</p>
<p>Returns the size of the workgroup at the given dimension.
The value is declared when instantiating the kernel.
This value is the same for all workitems in a given kernel,
even if they belong to different workgroups (i.e. each workgroups is &#8220;full&#8221;).</p>
</dd></dl>

<dl class="function">
<dt id="numba.hsa.get_group_id">
<code class="descclassname">numba.hsa.</code><code class="descname">get_group_id</code><span class="sig-paren">(</span><em>dim</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.hsa.get_group_id" title="Permalink to this definition">¶</a></dt>
<dd><p>Takes the index of the dimension being queried</p>
<p>Returns the workgroup ID in the ndrange of workgroup launched a kernel.</p>
</dd></dl>

<dl class="function">
<dt id="numba.hsa.get_global_id">
<code class="descclassname">numba.hsa.</code><code class="descname">get_global_id</code><span class="sig-paren">(</span><em>dim</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.hsa.get_global_id" title="Permalink to this definition">¶</a></dt>
<dd><p>Takes the index of the dimension being queried</p>
<p>Returns the global workitem ID for the given dimension.  Unlike <cite>numba.hsa
.get_local_id()</cite>, this number is unique for all workitems in a NDrange.</p>
</dd></dl>

</div>
</div>


                </div>
              </div>
            </div>
          </div>
        </div>
        
        
      </div><!-- /row -->

      <!-- row -->
      <div class="row-fluid">
<div class="related navbar ">
  <div class="navbar-inner">
    <ul class="nav pull-right">
      
        <li><a href="../genindex.html" title="General Index" >index</a></li>
        <li><a href="memory.html" title="5.3. Memory management" >next</a></li>
        <li><a href="overview.html" title="5.1. Overview" >previous</a></li>
        <li><a href="../index.html">Numba 0.21.0+242.gf3c4657-py2.7-linux-x86_64.egg documentation</a></li>
        <li><a href="index.html" >5. Numba for HSA APUs</a></li> 
      
    </ul>
  </div>
</div>
      </div><!-- /row -->

      <!-- footer -->
      <footer>
          &copy; Copyright 2012-2015, Continuum Analytics.
        Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.3.1.
      </footer>
      <!-- /footer -->

    </div>
    <!-- /container -->

  </body>
</html>