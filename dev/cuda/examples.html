<!DOCTYPE html>




<html lang="en">
  <head>
    <meta charset="utf-8" />
    
    <title>3.9. Examples &mdash; Numba 0.27.0.dev0+68.gaac985e-py2.7-linux-x86_64.egg documentation</title>

    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">
    <meta name="author" content="">

    
<link rel="stylesheet" href="../_static/css/basicstrap-base.css" type="text/css" />
<link rel="stylesheet" href="../_static/css/bootstrap.min.css" type="text/css" />
<link rel="stylesheet" href="../_static/css/font-awesome.min.css">
<!--[if IE 7]>
<link rel="stylesheet" href="../_static/css/font-awesome-ie7.min.css">
<![endif]-->
<style type="text/css">
  body {
    padding-top: 60px;
    padding-bottom: 40px;
  }
}
</style>
<link rel="stylesheet" href="../_static/basicstrap.css" type="text/css" />
<link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
<link rel="stylesheet" href="../_static/css/bootstrap-responsive.min.css" type="text/css" />
    
<script type="text/javascript">
  var DOCUMENTATION_OPTIONS = {
            URL_ROOT:    '../',
            VERSION:     '0.27.0.dev0+68.gaac985e-py2.7-linux-x86_64.egg',
            COLLAPSE_INDEX: false,
            FILE_SUFFIX: '.html',
            HAS_SOURCE:  true
  };
</script>
<script type="text/javascript" src="../_static/js/jquery.min.js"></script>
<script type="text/javascript" src="../_static/underscore.js"></script>
<script type="text/javascript" src="../_static/doctools.js"></script>
<script type="text/javascript" src="../_static/js/bootstrap.min.js"></script>
<script type="text/javascript">
  $(document).ready(function(){
    $('.show-sidebar').click(function(e) {
       e.preventDefault();
       if ($(".show-sidebar").html() == "Open Table Of Contents") {
          $('.for-mobile').removeClass('hidden-phone');
          $(".show-sidebar").html("Close Table Of Contents");
       } else {
          $(".show-sidebar").html("Open Table Of Contents");
       }
    });
  });
</script>
    <link rel="top" title="Numba 0.27.0.dev0+68.gaac985e-py2.7-linux-x86_64.egg documentation" href="../index.html" />
    <link rel="up" title="3. Numba for CUDA GPUs" href="index.html" />
    <link rel="next" title="3.10. Debugging CUDA Python with the the CUDA Simulator" href="simulator.html" />
    <link rel="prev" title="3.7. Device management" href="device-management.html" /> 
  </head>
  <body>
    <div class="navbar navbar-fixed-top ">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="../index.html">Numba 0.27.0.dev0+68.gaac985e-py2.7-linux-x86_64.egg documentation</a>
          <div class="nav-collapse collapse">
            <ul class="nav pull-right">
              
                <li>
                <a href="../genindex.html" title="General Index" accesskey="I">index</a>
                </li>
                <li>
                <a href="../py-modindex.html" title="Python Module Index" >modules</a>
                </li>
                <li>
                <a href="simulator.html" title="3.10. Debugging CUDA Python with the the CUDA Simulator" accesskey="N">next</a>
                </li>
                <li>
                <a href="device-management.html" title="3.7. Device management" accesskey="P">previous</a>
                </li>
                <li>
                <a href="index.html" accesskey="U">3. Numba for CUDA GPUs</a>
                </li>
              
            </ul>
          </div>
        </div>
      </div>
    </div>
    

    <!-- container -->
    <div class="container-fluid">


      
      <div class="row-fluid hidden-desktop hidden-tablet">
      
<div class="span3 ">
  <a class="visible-phone btn btn-small show-sidebar" data-toggle="collapse" data-target=".for-mobile">Open Table Of Contents</a>
  <div class="for-mobile sidebar hidden-phone">
  <h3><a href="../index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">3.9. Examples</a><ul>
<li><a class="reference internal" href="#matrix-multiplication">3.9.1. Matrix multiplication</a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="device-management.html"
                        title="previous chapter">3.7. Device management</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="simulator.html"
                        title="next chapter">3.10. Debugging CUDA Python with the the CUDA Simulator</a></p>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../_sources/cuda/examples.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox">
  <h3>Quick search</h3>
  <form class="search form-search" action="../search.html" method="get">
      <div class="input-append">
        <input type="text" class="search-query" name="q">
        <input type="submit" class="btn" value="Go" />
      </div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
  </div>
</div>
      </div>
      

      <!-- row -->
      <div class="row-fluid">
         
<div class="span3 visible-desktop visible-tablet">
  <div class=" sidebar hidden-phone">
  <h3><a href="../index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">3.9. Examples</a><ul>
<li><a class="reference internal" href="#matrix-multiplication">3.9.1. Matrix multiplication</a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="device-management.html"
                        title="previous chapter">3.7. Device management</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="simulator.html"
                        title="next chapter">3.10. Debugging CUDA Python with the the CUDA Simulator</a></p>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../_sources/cuda/examples.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox">
  <h3>Quick search</h3>
  <form class="search form-search" action="../search.html" method="get">
      <div class="input-append">
        <input type="text" class="search-query" name="q">
        <input type="submit" class="btn" value="Go" />
      </div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
  </div>
</div> 
        

        <div class="span9">
          <div class="document">
            <div class="documentwrapper">
              <div class="bodywrapper">
                <div class="body">
                  
  <div class="section" id="examples">
<h1>3.9. Examples<a class="headerlink" href="#examples" title="Permalink to this headline">¶</a></h1>
<div class="section" id="matrix-multiplication">
<span id="cuda-matmul"></span><h2>3.9.1. Matrix multiplication<a class="headerlink" href="#matrix-multiplication" title="Permalink to this headline">¶</a></h2>
<p>Here is a naive implementation of matrix multiplication using a CUDA kernel:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="nd">@cuda.jit</span>
<span class="k">def</span> <span class="nf">matmul</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">C</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Perform square matrix multiplication of C = A * B</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">i</span><span class="p">,</span> <span class="n">j</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">C</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">and</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">C</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
        <span class="n">tmp</span> <span class="o">=</span> <span class="mf">0.</span>
        <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="n">tmp</span> <span class="o">+=</span> <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="n">B</span><span class="p">[</span><span class="n">k</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span>
        <span class="n">C</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">tmp</span>
</pre></div>
</div>
<p>This implementation is straightforward and intuitive but performs poorly,
because the same matrix elements will be loaded multiple times from device
memory, which is slow (some devices may have transparent data caches, but
they may not be large enough to hold the entire inputs at once).</p>
<p>It will be faster if we use a blocked algorithm to reduce accesses to the
device memory.  CUDA provides a fast <a class="reference internal" href="memory.html#cuda-shared-memory"><span>shared memory</span></a>
for threads in a block to cooperately compute on a task.  The following
implements a faster version of the square matrix multiplication using shared
memory:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">numba</span> <span class="kn">import</span> <span class="n">cuda</span><span class="p">,</span> <span class="n">float32</span>

<span class="c"># Controls threads per block and shared memory usage.</span>
<span class="c"># The computation will be done on blocks of TPBxTPB elements.</span>
<span class="n">TPB</span> <span class="o">=</span> <span class="mi">16</span>

<span class="nd">@cuda.jit</span>
<span class="k">def</span> <span class="nf">fast_matmul</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">C</span><span class="p">):</span>
    <span class="c"># Define an array in the shared memory</span>
    <span class="c"># The size and type of the arrays must be known at compile time</span>
    <span class="n">sA</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">shared</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">TPB</span><span class="p">,</span> <span class="n">TPB</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">sB</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">shared</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">TPB</span><span class="p">,</span> <span class="n">TPB</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">float32</span><span class="p">)</span>

    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

    <span class="n">tx</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">threadIdx</span><span class="o">.</span><span class="n">x</span>
    <span class="n">ty</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">threadIdx</span><span class="o">.</span><span class="n">y</span>
    <span class="n">bpg</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">gridDim</span><span class="o">.</span><span class="n">x</span>    <span class="c"># blocks per grid</span>

    <span class="k">if</span> <span class="n">x</span> <span class="o">&gt;=</span> <span class="n">C</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">and</span> <span class="n">y</span> <span class="o">&gt;=</span> <span class="n">C</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
        <span class="c"># Quit if (x, y) is outside of valid C boundary</span>
        <span class="k">return</span>

    <span class="c"># Each thread computes one element in the result matrix.</span>
    <span class="c"># The dot product is chunked into dot products of TPB-long vectors.</span>
    <span class="n">tmp</span> <span class="o">=</span> <span class="mf">0.</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">bpg</span><span class="p">):</span>
        <span class="c"># Preload data into shared memory</span>
        <span class="n">sA</span><span class="p">[</span><span class="n">tx</span><span class="p">,</span> <span class="n">ty</span><span class="p">]</span> <span class="o">=</span> <span class="n">A</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">ty</span> <span class="o">+</span> <span class="n">i</span> <span class="o">*</span> <span class="n">TPB</span><span class="p">]</span>
        <span class="n">sB</span><span class="p">[</span><span class="n">tx</span><span class="p">,</span> <span class="n">ty</span><span class="p">]</span> <span class="o">=</span> <span class="n">B</span><span class="p">[</span><span class="n">tx</span> <span class="o">+</span> <span class="n">i</span> <span class="o">*</span> <span class="n">TPB</span><span class="p">,</span> <span class="n">y</span><span class="p">]</span>

        <span class="c"># Wait until all threads finish preloading</span>
        <span class="n">cuda</span><span class="o">.</span><span class="n">syncthreads</span><span class="p">()</span>

        <span class="c"># Computes partial product on the shared memory</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">TPB</span><span class="p">):</span>
            <span class="n">tmp</span> <span class="o">+=</span> <span class="n">sA</span><span class="p">[</span><span class="n">tx</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span> <span class="o">*</span> <span class="n">sB</span><span class="p">[</span><span class="n">j</span><span class="p">,</span> <span class="n">ty</span><span class="p">]</span>

        <span class="c"># Wait until all threads finish computing</span>
        <span class="n">cuda</span><span class="o">.</span><span class="n">syncthreads</span><span class="p">()</span>

    <span class="n">C</span><span class="p">[</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">]</span> <span class="o">=</span> <span class="n">tmp</span>
</pre></div>
</div>
<p>Because the shared memory is a limited resources, the code preloads small
block at a time from the input arrays.  Then, it calls
<a class="reference internal" href="../cuda-reference/kernel.html#numba.cuda.syncthreads" title="numba.cuda.syncthreads"><code class="xref py py-func docutils literal"><span class="pre">syncthreads()</span></code></a> to wait until all threads have finished
preloading and before doing the computation on the shared memory.
It synchronizes again after the computation to ensure all threads
have finished with the data in shared memory before overwriting it
in the next loop iteration.</p>
</div>
</div>


                </div>
              </div>
            </div>
          </div>
        </div>
        
        
      </div><!-- /row -->

      <!-- row -->
      <div class="row-fluid">
<div class="related navbar ">
  <div class="navbar-inner">
    <ul class="nav pull-right">
      
        <li><a href="../genindex.html" title="General Index" >index</a></li>
        <li><a href="../py-modindex.html" title="Python Module Index" >modules</a></li>
        <li><a href="simulator.html" title="3.10. Debugging CUDA Python with the the CUDA Simulator" >next</a></li>
        <li><a href="device-management.html" title="3.7. Device management" >previous</a></li>
        <li><a href="../index.html">Numba 0.27.0.dev0+68.gaac985e-py2.7-linux-x86_64.egg documentation</a></li>
        <li><a href="index.html" >3. Numba for CUDA GPUs</a></li> 
      
    </ul>
  </div>
</div>
      </div><!-- /row -->

      <!-- footer -->
      <footer>
          &copy; Copyright 2012-2015, Continuum Analytics.
        Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.3.1.
      </footer>
      <!-- /footer -->

    </div>
    <!-- /container -->

  </body>
</html>