<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>1.3. Installation &#8212; Numba 0.46.0.dev0+566.g5bd018f-py3.7-linux-x86_64.egg documentation</title>
    <link rel="stylesheet" href="../_static/bootstrap-sphinx.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/numba-docs.css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="1.4. Compiling Python code with @jit" href="jit.html" />
    <link rel="prev" title="1.2. Overview" href="overview.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">
<script type="text/javascript" src="../_static/js/jquery-1.11.0.min.js "></script>
<script type="text/javascript" src="../_static/js/jquery-fix.js "></script>
<script type="text/javascript" src="../_static/bootstrap-3.3.7/js/bootstrap.min.js "></script>
<script type="text/javascript" src="../_static/bootstrap-sphinx.js "></script>

  </head><body>

  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="../index.html"><span><img src="../_static/numba_blue_icon_rgb.png"></span>
          Numba</a>
        <span class="navbar-text navbar-version pull-left"><b>0.46</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="../index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="index.html">1. User Manual</a></li>
<li class="toctree-l1"><a class="reference internal" href="../reference/index.html">2. Reference Manual</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cuda/index.html">3. Numba for CUDA GPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cuda-reference/index.html">4. CUDA Python Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../roc/index.html">5. Numba for AMD ROC GPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../extending/index.html">6. Extending Numba</a></li>
<li class="toctree-l1"><a class="reference internal" href="../developer/index.html">7. Developer Manual</a></li>
<li class="toctree-l1"><a class="reference internal" href="../proposals/index.html">8. Numba Enhancement Proposals</a></li>
<li class="toctree-l1"><a class="reference internal" href="../glossary.html">9. Glossary</a></li>
<li class="toctree-l1"><a class="reference internal" href="../release-notes.html">10. Release Notes</a></li>
</ul>
</ul>
</li>
              
                <li class="dropdown">
  <a role="button"
     id="dLabelLocalToc"
     data-toggle="dropdown"
     data-target="#"
     href="#">Page <b class="caret"></b></a>
  <ul class="dropdown-menu localtoc"
      role="menu"
      aria-labelledby="dLabelLocalToc"><ul>
<li><a class="reference internal" href="#">1.3. Installation</a><ul>
<li><a class="reference internal" href="#compatibility">1.3.1. Compatibility</a></li>
<li><a class="reference internal" href="#installing-using-conda-on-x86-x86-64-power-platforms">1.3.2. Installing using conda on x86/x86_64/POWER Platforms</a></li>
<li><a class="reference internal" href="#installing-using-pip-on-x86-x86-64-platforms">1.3.3. Installing using pip on x86/x86_64 Platforms</a></li>
<li><a class="reference internal" href="#enabling-amd-rocm-gpu-support">1.3.4. Enabling AMD ROCm GPU Support</a></li>
<li><a class="reference internal" href="#installing-on-linux-armv7-platforms">1.3.5. Installing on Linux ARMv7 Platforms</a></li>
<li><a class="reference internal" href="#installing-on-linux-armv8-aarch64-platforms">1.3.6. Installing on Linux ARMv8 (AArch64) Platforms</a></li>
<li><a class="reference internal" href="#installing-from-source">1.3.7. Installing from source</a></li>
<li><a class="reference internal" href="#dependency-list">1.3.8. Dependency List</a></li>
<li><a class="reference internal" href="#checking-your-installation">1.3.9. Checking your installation</a></li>
</ul>
</li>
</ul>
</ul>
</li>
              
            
            
              
                
  <li>
    <a href="overview.html" title="Previous Chapter: 1.2. Overview"><span class="glyphicon glyphicon-chevron-left visible-sm"></span><span class="hidden-sm hidden-tablet">&laquo; 1.2. Overview</span>
    </a>
  </li>
  <li>
    <a href="jit.html" title="Next Chapter: 1.4. Compiling Python code with @jit"><span class="glyphicon glyphicon-chevron-right visible-sm"></span><span class="hidden-sm hidden-tablet">1.4. Compilin... &raquo;</span>
    </a>
  </li>
              
            
            
            
            
              <li class="hidden-sm">
<div id="sourcelink">
  <a href="../_sources/user/installing.rst.txt"
     rel="nofollow">Source</a>
</div></li>
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="../search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
    <div class="body col-md-12 content" role="main">
      
  <div class="section" id="installation">
<h1>1.3. Installation<a class="headerlink" href="#installation" title="Permalink to this headline">¶</a></h1>
<div class="section" id="compatibility">
<h2>1.3.1. Compatibility<a class="headerlink" href="#compatibility" title="Permalink to this headline">¶</a></h2>
<p>Numba is compatible with Python 2.7 and 3.5 or later, and Numpy versions 1.7 to
1.16.</p>
<p>Our supported platforms are:</p>
<ul class="simple">
<li>Linux x86 (32-bit and 64-bit)</li>
<li>Linux ppcle64 (POWER8)</li>
<li>Windows 7 and later (32-bit and 64-bit)</li>
<li>OS X 10.9 and later (64-bit)</li>
<li>NVIDIA GPUs of compute capability 2.0 and later</li>
<li>AMD ROC dGPUs (linux only and not for AMD Carrizo or Kaveri APU)</li>
<li>ARMv7 (32-bit little-endian, such as Raspberry Pi 2 and 3)</li>
<li>ARMv8 (64-bit little-endian, such as the NVIDIA Jetson)</li>
</ul>
<p><a class="reference internal" href="parallel.html#numba-parallel"><span class="std std-ref">Automatic parallelization with &#64;jit</span></a> is only available on 64-bit platforms,
and is not supported in Python 2.7 on Windows.</p>
</div>
<div class="section" id="installing-using-conda-on-x86-x86-64-power-platforms">
<h2>1.3.2. Installing using conda on x86/x86_64/POWER Platforms<a class="headerlink" href="#installing-using-conda-on-x86-x86-64-power-platforms" title="Permalink to this headline">¶</a></h2>
<p>The easiest way to install Numba and get updates is by using <code class="docutils literal notranslate"><span class="pre">conda</span></code>,
a cross-platform package manager and software distribution maintained
by Anaconda, Inc.  You can either use <a class="reference external" href="https://www.anaconda.com/download">Anaconda</a> to get the full stack in one download,
or <a class="reference external" href="https://conda.io/miniconda.html">Miniconda</a> which will install
the minimum packages required for a conda environment.</p>
<p>Once you have conda installed, just type:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ conda install numba
</pre></div>
</div>
<p>or:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ conda update numba
</pre></div>
</div>
<p>Note that Numba, like Anaconda, only supports PPC in 64-bit little-endian mode.</p>
<p>To enable CUDA GPU support for Numba, install the latest <a class="reference external" href="https://www.nvidia.com/Download/index.aspx">graphics drivers from
NVIDIA</a> for your platform.
(Note that the open source Nouveau drivers shipped by default with many Linux
distributions do not support CUDA.)  Then install the <code class="docutils literal notranslate"><span class="pre">cudatoolkit</span></code> package:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ conda install cudatoolkit
</pre></div>
</div>
<p>You do not need to install the CUDA SDK from NVIDIA.</p>
</div>
<div class="section" id="installing-using-pip-on-x86-x86-64-platforms">
<h2>1.3.3. Installing using pip on x86/x86_64 Platforms<a class="headerlink" href="#installing-using-pip-on-x86-x86-64-platforms" title="Permalink to this headline">¶</a></h2>
<p>Binary wheels for Windows, Mac, and Linux are also available from <a class="reference external" href="https://pypi.org/project/numba/">PyPI</a>.  You can install Numba using <code class="docutils literal notranslate"><span class="pre">pip</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ pip install numba
</pre></div>
</div>
<p>This will download all of the needed dependencies as well.  You do not need to
have LLVM installed to use Numba (in fact, Numba will ignore all LLVM
versions installed on the system) as the required components are bundled into
the llvmlite wheel.</p>
<p>To use CUDA with Numba installed by <cite>pip</cite>, you need to install the <a class="reference external" href="https://developer.nvidia.com/cuda-downloads">CUDA SDK</a> from NVIDIA.  Please refer to
<a class="reference internal" href="../cuda/overview.html#cudatoolkit-lookup"><span class="std std-ref">Setting CUDA Installation Path</span></a> for details. Numba can also detect CUDA libraries
installed system-wide on Linux.</p>
</div>
<div class="section" id="enabling-amd-rocm-gpu-support">
<h2>1.3.4. Enabling AMD ROCm GPU Support<a class="headerlink" href="#enabling-amd-rocm-gpu-support" title="Permalink to this headline">¶</a></h2>
<p>The <a class="reference external" href="https://rocm.github.io/">ROCm Platform</a> allows GPU computing with AMD
GPUs on Linux.  To enable ROCm support in Numba,  conda is required, so begin
with an Anaconda or Miniconda installation with Numba 0.40 or later installed.
Then:</p>
<ol class="arabic">
<li><p class="first">Follow the <a class="reference external" href="https://rocm.github.io/install.html">ROCm installation instructions</a>.</p>
</li>
<li><p class="first">Install <code class="docutils literal notranslate"><span class="pre">roctools</span></code> conda package from the <code class="docutils literal notranslate"><span class="pre">numba</span></code> channel:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ conda install -c numba roctools
</pre></div>
</div>
</li>
</ol>
<p>See the <a class="reference external" href="https://github.com/numba/roc-examples">roc-examples</a> repository for
sample notebooks.</p>
</div>
<div class="section" id="installing-on-linux-armv7-platforms">
<span id="numba-install-armv7"></span><h2>1.3.5. Installing on Linux ARMv7 Platforms<a class="headerlink" href="#installing-on-linux-armv7-platforms" title="Permalink to this headline">¶</a></h2>
<p><a class="reference external" href="https://github.com/jjhelmus/berryconda">Berryconda</a> is a
conda-based Python distribution for the Raspberry Pi.  We are now uploading
packages to the <code class="docutils literal notranslate"><span class="pre">numba</span></code> channel on Anaconda Cloud for 32-bit little-endian,
ARMv7-based boards, which currently includes the Raspberry Pi 2 and 3,
but not the Pi 1 or Zero.  These can be installed using conda from the
<code class="docutils literal notranslate"><span class="pre">numba</span></code> channel:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ conda install -c numba numba
</pre></div>
</div>
<p>Berryconda and Numba may work on other Linux-based ARMv7 systems, but this has
not been tested.</p>
</div>
<div class="section" id="installing-on-linux-armv8-aarch64-platforms">
<h2>1.3.6. Installing on Linux ARMv8 (AArch64) Platforms<a class="headerlink" href="#installing-on-linux-armv8-aarch64-platforms" title="Permalink to this headline">¶</a></h2>
<p>We build and test conda packages on the <a class="reference external" href="https://www.nvidia.com/en-us/autonomous-machines/embedded-systems-dev-kits-modules/">NVIDIA Jetson TX2</a>,
but they are likely to work for other AArch64 platforms.  (Note that while the
Raspberry Pi CPU is 64-bit, Raspbian runs it in 32-bit mode, so look at
<a class="reference internal" href="#numba-install-armv7"><span class="std std-ref">Installing on Linux ARMv7 Platforms</span></a> instead.)</p>
<p>Conda-forge support for AArch64 is still quite experimental and packages are limited,
but it does work enough for Numba to build and pass tests.  To set up the environment:</p>
<ul>
<li><p class="first">Install <a class="reference external" href="https://github.com/jjhelmus/conda4aarch64/releases">conda4aarch64</a>.
This will create a minimal conda environment.</p>
</li>
<li><p class="first">Add the <code class="docutils literal notranslate"><span class="pre">c4aarch64</span></code> and <code class="docutils literal notranslate"><span class="pre">conda-forge</span></code> channels to your conda
configuration:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ conda config --add channels c4aarch64
$ conda config --add channels conda-forge
</pre></div>
</div>
</li>
<li><p class="first">Then you can install Numba from the <code class="docutils literal notranslate"><span class="pre">numba</span></code> channel:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ conda install -c numba numba
</pre></div>
</div>
</li>
</ul>
<p>On CUDA-enabled systems, like the Jetson, the CUDA toolkit should be
automatically detected in the environment.</p>
</div>
<div class="section" id="installing-from-source">
<span id="numba-source-install-instructions"></span><h2>1.3.7. Installing from source<a class="headerlink" href="#installing-from-source" title="Permalink to this headline">¶</a></h2>
<p>Installing Numba from source is fairly straightforward (similar to other
Python packages), but installing <a class="reference external" href="https://github.com/numba/llvmlite">llvmlite</a> can be quite challenging due to the need
for a special LLVM build.  If you are building from source for the purposes of
Numba development, see <a class="reference internal" href="../developer/contributing.html#buildenv"><span class="std std-ref">Build environment</span></a> for details on how to create a Numba
development environment with conda.</p>
<p>If you are building Numba from source for other reasons, first follow the
<a class="reference external" href="https://llvmlite.readthedocs.io/en/latest/admin-guide/install.html">llvmlite installation guide</a>.
Once that is completed, you can download the latest Numba source code from
<a class="reference external" href="https://github.com/numba/numba">Github</a>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ git clone git://github.com/numba/numba.git
</pre></div>
</div>
<p>Source archives of the latest release can also be found on
<a class="reference external" href="https://pypi.org/project/numba/">PyPI</a>.  In addition to <code class="docutils literal notranslate"><span class="pre">llvmlite</span></code>, you will also need:</p>
<ul class="simple">
<li>A C compiler compatible with your Python installation.  If you are using
Anaconda, you can use the following conda packages:<ul>
<li>Linux <code class="docutils literal notranslate"><span class="pre">x86</span></code>: <code class="docutils literal notranslate"><span class="pre">gcc_linux-32</span></code> and <code class="docutils literal notranslate"><span class="pre">gxx_linux-32</span></code></li>
<li>Linux <code class="docutils literal notranslate"><span class="pre">x86_64</span></code>: <code class="docutils literal notranslate"><span class="pre">gcc_linux-64</span></code> and <code class="docutils literal notranslate"><span class="pre">gxx_linux-64</span></code></li>
<li>Linux <code class="docutils literal notranslate"><span class="pre">POWER</span></code>: <code class="docutils literal notranslate"><span class="pre">gcc_linux-ppc64le</span></code> and <code class="docutils literal notranslate"><span class="pre">gxx_linux-ppc64le</span></code></li>
<li>Linux <code class="docutils literal notranslate"><span class="pre">ARM</span></code>: no conda packages, use the system compiler</li>
<li>Mac OSX: <code class="docutils literal notranslate"><span class="pre">clang_osx-64</span></code> and <code class="docutils literal notranslate"><span class="pre">clangxx_osx-64</span></code> or the system compiler at
<code class="docutils literal notranslate"><span class="pre">/usr/bin/clang</span></code> (Mojave onwards)</li>
<li>Windows: a version of Visual Studio appropriate for the Python version in
use</li>
</ul>
</li>
<li><a class="reference external" href="http://www.numpy.org/">NumPy</a></li>
</ul>
<p>Then you can build and install Numba from the top level of the source tree:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ python setup.py install
</pre></div>
</div>
</div>
<div class="section" id="dependency-list">
<span id="numba-source-install-check"></span><h2>1.3.8. Dependency List<a class="headerlink" href="#dependency-list" title="Permalink to this headline">¶</a></h2>
<p>Numba has numerous required and optional dependencies which additionally may
vary with target operating system and hardware. The following lists them all
(as of September 2019).</p>
<ul class="simple">
<li>Required build time:<ul>
<li><code class="docutils literal notranslate"><span class="pre">setuptools</span></code></li>
<li><code class="docutils literal notranslate"><span class="pre">numpy</span></code></li>
<li><code class="docutils literal notranslate"><span class="pre">llvmlite</span></code></li>
<li><code class="docutils literal notranslate"><span class="pre">funcsigs</span></code> (Python 2)</li>
<li><code class="docutils literal notranslate"><span class="pre">singledispatch</span></code> (Python 2)</li>
<li>Compiler toolchain mentioned above</li>
</ul>
</li>
<li>Optional build time:<ul>
<li><code class="docutils literal notranslate"><span class="pre">llvm-openmp</span></code> (OSX) - provides headers for compiling OpenMP support into
Numba’s threading backend</li>
<li><code class="docutils literal notranslate"><span class="pre">intel-openmp</span></code> (OSX) - provides OpenMP library support for Numba’s
threading backend.</li>
<li><code class="docutils literal notranslate"><span class="pre">tbb-devel</span></code> - provides TBB headers/libraries for compiling TBB support
into Numba’s threading backend</li>
</ul>
</li>
<li>Required run time:<ul>
<li><code class="docutils literal notranslate"><span class="pre">numpy</span></code></li>
<li><code class="docutils literal notranslate"><span class="pre">llvmlite</span></code></li>
<li><code class="docutils literal notranslate"><span class="pre">funcsigs</span></code> (Python 2)</li>
<li><code class="docutils literal notranslate"><span class="pre">singledispatch</span></code> (Python 2)</li>
</ul>
</li>
<li>Optional runtime are:<ul>
<li><code class="docutils literal notranslate"><span class="pre">scipy</span></code> - provides cython bindings used in Numba’s <code class="docutils literal notranslate"><span class="pre">np.linalg.*</span></code>
support</li>
<li><code class="docutils literal notranslate"><span class="pre">tbb</span></code> - provides the TBB runtime libraries used by Numba’s TBB threading
backend</li>
<li><code class="docutils literal notranslate"><span class="pre">jinja2</span></code> - for “pretty” type annotation output (HTML) via the <code class="docutils literal notranslate"><span class="pre">numba</span></code>
CLI</li>
<li><code class="docutils literal notranslate"><span class="pre">cffi</span></code> - permits use of CFFI bindings in Numba compiled functions</li>
<li><code class="docutils literal notranslate"><span class="pre">intel-openmp</span></code> - (OSX) provides OpenMP library support for Numba’s OpenMP
threading backend</li>
<li><code class="docutils literal notranslate"><span class="pre">ipython</span></code> - if in use, caching will use IPython’s cache
directories/caching still works</li>
<li><code class="docutils literal notranslate"><span class="pre">pyyaml</span></code> - permits the use of a <code class="docutils literal notranslate"><span class="pre">.numba_config.yaml</span></code>
file for storing per project configuration options</li>
<li><code class="docutils literal notranslate"><span class="pre">colorama</span></code> - makes error message highlighting work</li>
<li><code class="docutils literal notranslate"><span class="pre">icc_rt</span></code> - (numba channel) allows Numba to use Intel SVML for extra
performance</li>
<li><code class="docutils literal notranslate"><span class="pre">pygments</span></code> - for “pretty” type annotation</li>
<li><code class="docutils literal notranslate"><span class="pre">gdb</span></code> as an executable on the <code class="docutils literal notranslate"><span class="pre">$PATH</span></code> - if you would like to use the gdb
support</li>
<li>Compiler toolchain mentioned above, if you would like to use <code class="docutils literal notranslate"><span class="pre">pycc</span></code> for
Ahead-of-Time (AOT) compilation</li>
</ul>
</li>
<li>To build the documentation:<ul>
<li><code class="docutils literal notranslate"><span class="pre">sphinx</span></code></li>
<li><code class="docutils literal notranslate"><span class="pre">pygments</span></code></li>
<li><code class="docutils literal notranslate"><span class="pre">sphinx-bootstrap</span></code></li>
<li><code class="docutils literal notranslate"><span class="pre">numpydoc</span></code></li>
<li><code class="docutils literal notranslate"><span class="pre">make</span></code> as an executable on the <code class="docutils literal notranslate"><span class="pre">$PATH</span></code></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="checking-your-installation">
<h2>1.3.9. Checking your installation<a class="headerlink" href="#checking-your-installation" title="Permalink to this headline">¶</a></h2>
<p>You should be able to import Numba from the Python prompt:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ python
Python 2.7.15 |Anaconda custom (x86_64)| (default, May  1 2018, 18:37:05)
[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)] on darwin
Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.
&gt;&gt;&gt; import numba
&gt;&gt;&gt; numba.__version__
&#39;0.39.0+0.g4e49566.dirty&#39;
</pre></div>
</div>
<p>You can also try executing the <code class="docutils literal notranslate"><span class="pre">numba</span> <span class="pre">--sysinfo</span></code> (or <code class="docutils literal notranslate"><span class="pre">numba</span> <span class="pre">-s</span></code> for short)
command to report information about your system capabilities. See <a class="reference internal" href="cli.html#cli"><span class="std std-ref">Command line interface</span></a> for
further information.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ numba -s
System info:
--------------------------------------------------------------------------------
__Time Stamp__
2018-08-28 15:46:24.631054

__Hardware Information__
Machine                             : x86_64
CPU Name                            : haswell
CPU Features                        :
aes avx avx2 bmi bmi2 cmov cx16 f16c fma fsgsbase lzcnt mmx movbe pclmul popcnt
rdrnd sse sse2 sse3 sse4.1 sse4.2 ssse3 xsave xsaveopt

__OS Information__
Platform                            : Darwin-17.6.0-x86_64-i386-64bit
Release                             : 17.6.0
System Name                         : Darwin
Version                             : Darwin Kernel Version 17.6.0: Tue May  8 15:22:16 PDT 2018; root:xnu-4570.61.1~1/RELEASE_X86_64
OS specific info                    : 10.13.5   x86_64

__Python Information__
Python Compiler                     : GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)
Python Implementation               : CPython
Python Version                      : 2.7.15
Python Locale                       : en_US UTF-8

__LLVM information__
LLVM version                        : 6.0.0

__CUDA Information__
Found 1 CUDA devices
id 0         GeForce GT 750M                              [SUPPORTED]
                      compute capability: 3.0
                           pci device id: 0
                              pci bus id: 1
</pre></div>
</div>
<p>(output truncated due to length)</p>
</div>
</div>


    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
    </p>
    <p>
        &copy; Copyright 2012, Anaconda, Inc..<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.8.2.<br/>
    </p>
  </div>
</footer>
  </body>
</html>