<!DOCTYPE html>




<html lang="en">
  <head>
    <meta charset="utf-8" />
    
    <title>4.2. CUDA Kernel API &mdash; Numba 0.22.1+318.g54f93d9-py2.7-linux-x86_64.egg documentation</title>

    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">
    <meta name="author" content="">

    
<link rel="stylesheet" href="../_static/css/basicstrap-base.css" type="text/css" />
<link rel="stylesheet" href="../_static/css/bootstrap.min.css" type="text/css" />
<link rel="stylesheet" href="../_static/css/font-awesome.min.css">
<!--[if IE 7]>
<link rel="stylesheet" href="../_static/css/font-awesome-ie7.min.css">
<![endif]-->
<style type="text/css">
  body {
    padding-top: 60px;
    padding-bottom: 40px;
  }
}
</style>
<link rel="stylesheet" href="../_static/basicstrap.css" type="text/css" />
<link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
<link rel="stylesheet" href="../_static/css/bootstrap-responsive.min.css" type="text/css" />
    
<script type="text/javascript">
  var DOCUMENTATION_OPTIONS = {
            URL_ROOT:    '../',
            VERSION:     '0.22.1+318.g54f93d9-py2.7-linux-x86_64.egg',
            COLLAPSE_INDEX: false,
            FILE_SUFFIX: '.html',
            HAS_SOURCE:  true
  };
</script>
<script type="text/javascript" src="../_static/js/jquery.min.js"></script>
<script type="text/javascript" src="../_static/underscore.js"></script>
<script type="text/javascript" src="../_static/doctools.js"></script>
<script type="text/javascript" src="../_static/js/bootstrap.min.js"></script>
<script type="text/javascript">
  $(document).ready(function(){
    $('.show-sidebar').click(function(e) {
       e.preventDefault();
       if ($(".show-sidebar").html() == "Open Table Of Contents") {
          $('.for-mobile').removeClass('hidden-phone');
          $(".show-sidebar").html("Close Table Of Contents");
       } else {
          $(".show-sidebar").html("Open Table Of Contents");
       }
    });
  });
</script>
    <link rel="top" title="Numba 0.22.1+318.g54f93d9-py2.7-linux-x86_64.egg documentation" href="../index.html" />
    <link rel="up" title="4. CUDA Python Reference" href="index.html" />
    <link rel="next" title="4.3. Memory Management" href="memory.html" />
    <link rel="prev" title="4.1. CUDA Host API" href="host.html" /> 
  </head>
  <body>
    <div class="navbar navbar-fixed-top ">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="../index.html">Numba 0.22.1+318.g54f93d9-py2.7-linux-x86_64.egg documentation</a>
          <div class="nav-collapse collapse">
            <ul class="nav pull-right">
              
                <li>
                <a href="../genindex.html" title="General Index" accesskey="I">index</a>
                </li>
                <li>
                <a href="memory.html" title="4.3. Memory Management" accesskey="N">next</a>
                </li>
                <li>
                <a href="host.html" title="4.1. CUDA Host API" accesskey="P">previous</a>
                </li>
                <li>
                <a href="index.html" accesskey="U">4. CUDA Python Reference</a>
                </li>
              
            </ul>
          </div>
        </div>
      </div>
    </div>
    

    <!-- container -->
    <div class="container-fluid">


      
      <div class="row-fluid hidden-desktop hidden-tablet">
      
<div class="span3 ">
  <a class="visible-phone btn btn-small show-sidebar" data-toggle="collapse" data-target=".for-mobile">Open Table Of Contents</a>
  <div class="for-mobile sidebar hidden-phone">
  <h3><a href="../index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">4.2. CUDA Kernel API</a><ul>
<li><a class="reference internal" href="#kernel-declaration">4.2.1. Kernel declaration</a></li>
<li><a class="reference internal" href="#intrinsic-attributes-and-functions">4.2.2. Intrinsic Attributes and Functions</a><ul>
<li><a class="reference internal" href="#thread-indexing">4.2.2.1. Thread Indexing</a></li>
<li><a class="reference internal" href="#memory-management">4.2.2.2. Memory Management</a></li>
<li><a class="reference internal" href="#synchronization-and-atomic-operations">4.2.2.3. Synchronization and Atomic Operations</a></li>
<li><a class="reference internal" href="#memory-fences">4.2.2.4. Memory Fences</a></li>
</ul>
</li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="host.html"
                        title="previous chapter">4.1. CUDA Host API</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="memory.html"
                        title="next chapter">4.3. Memory Management</a></p>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../_sources/cuda-reference/kernel.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox">
  <h3>Quick search</h3>
  <form class="search form-search" action="../search.html" method="get">
      <div class="input-append">
        <input type="text" class="search-query" name="q">
        <input type="submit" class="btn" value="Go" />
      </div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
  </div>
</div>
      </div>
      

      <!-- row -->
      <div class="row-fluid">
         
<div class="span3 visible-desktop visible-tablet">
  <div class=" sidebar hidden-phone">
  <h3><a href="../index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">4.2. CUDA Kernel API</a><ul>
<li><a class="reference internal" href="#kernel-declaration">4.2.1. Kernel declaration</a></li>
<li><a class="reference internal" href="#intrinsic-attributes-and-functions">4.2.2. Intrinsic Attributes and Functions</a><ul>
<li><a class="reference internal" href="#thread-indexing">4.2.2.1. Thread Indexing</a></li>
<li><a class="reference internal" href="#memory-management">4.2.2.2. Memory Management</a></li>
<li><a class="reference internal" href="#synchronization-and-atomic-operations">4.2.2.3. Synchronization and Atomic Operations</a></li>
<li><a class="reference internal" href="#memory-fences">4.2.2.4. Memory Fences</a></li>
</ul>
</li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="host.html"
                        title="previous chapter">4.1. CUDA Host API</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="memory.html"
                        title="next chapter">4.3. Memory Management</a></p>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../_sources/cuda-reference/kernel.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox">
  <h3>Quick search</h3>
  <form class="search form-search" action="../search.html" method="get">
      <div class="input-append">
        <input type="text" class="search-query" name="q">
        <input type="submit" class="btn" value="Go" />
      </div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
  </div>
</div> 
        

        <div class="span9">
          <div class="document">
            <div class="documentwrapper">
              <div class="bodywrapper">
                <div class="body">
                  
  <div class="section" id="cuda-kernel-api">
<h1>4.2. CUDA Kernel API<a class="headerlink" href="#cuda-kernel-api" title="Permalink to this headline">¶</a></h1>
<div class="section" id="kernel-declaration">
<h2>4.2.1. Kernel declaration<a class="headerlink" href="#kernel-declaration" title="Permalink to this headline">¶</a></h2>
<p>The <code class="docutils literal"><span class="pre">&#64;cuda.jit</span></code> decorator is used to create a CUDA kernel:</p>
<dl class="function">
<dt id="numba.cuda.jit">
<code class="descclassname">numba.cuda.</code><code class="descname">jit</code><span class="sig-paren">(</span><em>func_or_sig=None</em>, <em>argtypes=None</em>, <em>device=False</em>, <em>inline=False</em>, <em>bind=True</em>, <em>link=[]</em>, <em>debug=False</em>, <em>**kws</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.jit" title="Permalink to this definition">¶</a></dt>
<dd><p>JIT compile a python function conforming to the CUDA Python specification.
If a signature is supplied, then a function is returned that takes a
function to compile. If</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>func_or_sig</strong> (<em>function or numba.typing.Signature</em>) &#8211; <p>A function to JIT compile, or a signature of a function
to compile. If a function is supplied, then an <code class="xref py py-class docutils literal"><span class="pre">AutoJitCUDAKernel</span></code>
is returned. If a signature is supplied, then a function which takes a
function to compile and returns an <code class="xref py py-class docutils literal"><span class="pre">AutoJitCUDAKernel</span></code> is
returned.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">A kernel cannot have any return value.</p>
</div>
</li>
<li><strong>device</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.5)"><em>bool</em></a>) &#8211; Indicates whether this is a device function.</li>
<li><strong>bind</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.5)"><em>bool</em></a>) &#8211; Force binding to CUDA context immediately</li>
<li><strong>link</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.5)"><em>list</em></a>) &#8211; A list of files containing PTX source to link with the function</li>
<li><strong>debug</strong> &#8211; If True, check for exceptions thrown when executing the
kernel. Since this degrades performance, this should only be used for
debugging purposes.</li>
<li><strong>fastmath</strong> &#8211; If true, enables flush-to-zero and fused-multiply-add,
disables precise division and square root. This parameter has no effect
on device function, whose fastmath setting depends on the kernel function
from which they are called.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="class">
<dt id="numba.cuda.compiler.AutoJitCUDAKernel">
<em class="property">class </em><code class="descclassname">numba.cuda.compiler.</code><code class="descname">AutoJitCUDAKernel</code><span class="sig-paren">(</span><em>func</em>, <em>bind</em>, <em>targetoptions</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.compiler.AutoJitCUDAKernel" title="Permalink to this definition">¶</a></dt>
<dd><p>CUDA Kernel object. When called, the kernel object will specialize itself
for the given arguments (if no suitable specialized version already exists)
and launch on the device associated with the current context.</p>
<p>Kernel objects are not to be constructed by the user, but instead are
created using the <a class="reference internal" href="#numba.cuda.jit" title="numba.cuda.jit"><code class="xref py py-func docutils literal"><span class="pre">numba.cuda.jit()</span></code></a> decorator.</p>
<dl class="method">
<dt id="numba.cuda.compiler.AutoJitCUDAKernel.inspect_asm">
<code class="descname">inspect_asm</code><span class="sig-paren">(</span><em>signature=None</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.compiler.AutoJitCUDAKernel.inspect_asm" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the generated assembly code for all signatures encountered thus
far, or the LLVM IR for a specific signature if given.</p>
</dd></dl>

<dl class="method">
<dt id="numba.cuda.compiler.AutoJitCUDAKernel.inspect_llvm">
<code class="descname">inspect_llvm</code><span class="sig-paren">(</span><em>signature=None</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.compiler.AutoJitCUDAKernel.inspect_llvm" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the LLVM IR for all signatures encountered thus far, or the LLVM
IR for a specific signature if given.</p>
</dd></dl>

<dl class="method">
<dt id="numba.cuda.compiler.AutoJitCUDAKernel.inspect_types">
<code class="descname">inspect_types</code><span class="sig-paren">(</span><em>file=None</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.compiler.AutoJitCUDAKernel.inspect_types" title="Permalink to this definition">¶</a></dt>
<dd><p>Produce a dump of the Python source of this function annotated with the
corresponding Numba IR and type information. The dump is written to
<em>file</em>, or <em>sys.stdout</em> if <em>file</em> is <em>None</em>.</p>
</dd></dl>

<dl class="method">
<dt id="numba.cuda.compiler.AutoJitCUDAKernel.specialize">
<code class="descname">specialize</code><span class="sig-paren">(</span><em>*args</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.compiler.AutoJitCUDAKernel.specialize" title="Permalink to this definition">¶</a></dt>
<dd><p>Compile and bind to the current context a version of this kernel
specialized for the given <em>args</em>.</p>
</dd></dl>

</dd></dl>

<p>Individual specialized kernels are instances of
<a class="reference internal" href="#numba.cuda.compiler.CUDAKernel" title="numba.cuda.compiler.CUDAKernel"><code class="xref py py-class docutils literal"><span class="pre">numba.cuda.compiler.CUDAKernel</span></code></a>:</p>
<dl class="class">
<dt id="numba.cuda.compiler.CUDAKernel">
<em class="property">class </em><code class="descclassname">numba.cuda.compiler.</code><code class="descname">CUDAKernel</code><span class="sig-paren">(</span><em>llvm_module</em>, <em>name</em>, <em>pretty_name</em>, <em>argtypes</em>, <em>call_helper</em>, <em>link=()</em>, <em>debug=False</em>, <em>fastmath=False</em>, <em>type_annotation=None</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.compiler.CUDAKernel" title="Permalink to this definition">¶</a></dt>
<dd><p>CUDA Kernel specialized for a given set of argument types. When called, this
object will validate that the argument types match those for which it is
specialized, and then launch the kernel on the device.</p>
<dl class="method">
<dt id="numba.cuda.compiler.CUDAKernel.bind">
<code class="descname">bind</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.compiler.CUDAKernel.bind" title="Permalink to this definition">¶</a></dt>
<dd><p>Force binding to current CUDA context</p>
</dd></dl>

<dl class="attribute">
<dt id="numba.cuda.compiler.CUDAKernel.device">
<code class="descname">device</code><a class="headerlink" href="#numba.cuda.compiler.CUDAKernel.device" title="Permalink to this definition">¶</a></dt>
<dd><p>Get current active context</p>
</dd></dl>

<dl class="method">
<dt id="numba.cuda.compiler.CUDAKernel.inspect_asm">
<code class="descname">inspect_asm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.compiler.CUDAKernel.inspect_asm" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the PTX code for this kernel.</p>
</dd></dl>

<dl class="method">
<dt id="numba.cuda.compiler.CUDAKernel.inspect_llvm">
<code class="descname">inspect_llvm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.compiler.CUDAKernel.inspect_llvm" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the LLVM IR for this kernel.</p>
</dd></dl>

<dl class="method">
<dt id="numba.cuda.compiler.CUDAKernel.inspect_types">
<code class="descname">inspect_types</code><span class="sig-paren">(</span><em>file=None</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.compiler.CUDAKernel.inspect_types" title="Permalink to this definition">¶</a></dt>
<dd><p>Produce a dump of the Python source of this function annotated with the
corresponding Numba IR and type information. The dump is written to
<em>file</em>, or <em>sys.stdout</em> if <em>file</em> is <em>None</em>.</p>
</dd></dl>

<dl class="attribute">
<dt id="numba.cuda.compiler.CUDAKernel.ptx">
<code class="descname">ptx</code><a class="headerlink" href="#numba.cuda.compiler.CUDAKernel.ptx" title="Permalink to this definition">¶</a></dt>
<dd><p>PTX code for this kernel.</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="intrinsic-attributes-and-functions">
<h2>4.2.2. Intrinsic Attributes and Functions<a class="headerlink" href="#intrinsic-attributes-and-functions" title="Permalink to this headline">¶</a></h2>
<p>The remainder of the attributes and functions in this section may only be called
from within a CUDA Kernel.</p>
<div class="section" id="thread-indexing">
<h3>4.2.2.1. Thread Indexing<a class="headerlink" href="#thread-indexing" title="Permalink to this headline">¶</a></h3>
<dl class="attribute">
<dt id="numba.cuda.threadIdx">
<code class="descclassname">numba.cuda.</code><code class="descname">threadIdx</code><a class="headerlink" href="#numba.cuda.threadIdx" title="Permalink to this definition">¶</a></dt>
<dd><p>The thread indices in the current thread block, accessed through the
attributes <code class="docutils literal"><span class="pre">x</span></code>, <code class="docutils literal"><span class="pre">y</span></code>, and <code class="docutils literal"><span class="pre">z</span></code>. Each index is an integer spanning the
range from 0 inclusive to the corresponding value of the attribute in
<a class="reference internal" href="#numba.cuda.blockDim" title="numba.cuda.blockDim"><code class="xref py py-attr docutils literal"><span class="pre">numba.cuda.blockDim</span></code></a> exclusive.</p>
</dd></dl>

<dl class="attribute">
<dt id="numba.cuda.blockIdx">
<code class="descclassname">numba.cuda.</code><code class="descname">blockIdx</code><a class="headerlink" href="#numba.cuda.blockIdx" title="Permalink to this definition">¶</a></dt>
<dd><p>The block indices in the grid of thread blocks, accessed through the
attributes <code class="docutils literal"><span class="pre">x</span></code>, <code class="docutils literal"><span class="pre">y</span></code>, and <code class="docutils literal"><span class="pre">z</span></code>. Each index is an integer spanning the
range from 0 inclusive to the corresponding value of the attribute in
<a class="reference internal" href="#numba.cuda.gridDim" title="numba.cuda.gridDim"><code class="xref py py-attr docutils literal"><span class="pre">numba.cuda.gridDim</span></code></a> exclusive.</p>
</dd></dl>

<dl class="attribute">
<dt id="numba.cuda.blockDim">
<code class="descclassname">numba.cuda.</code><code class="descname">blockDim</code><a class="headerlink" href="#numba.cuda.blockDim" title="Permalink to this definition">¶</a></dt>
<dd><p>The shape of a block of threads, as declared when instantiating the
kernel.  This value is the same for all threads in a given kernel, even
if they belong to different blocks (i.e. each block is &#8220;full&#8221;).</p>
</dd></dl>

<dl class="attribute">
<dt id="numba.cuda.gridDim">
<code class="descclassname">numba.cuda.</code><code class="descname">gridDim</code><a class="headerlink" href="#numba.cuda.gridDim" title="Permalink to this definition">¶</a></dt>
<dd><p>The shape of the grid of blocks, accressed through the attributes <code class="docutils literal"><span class="pre">x</span></code>,
<code class="docutils literal"><span class="pre">y</span></code>, and <code class="docutils literal"><span class="pre">z</span></code>.</p>
</dd></dl>

<dl class="function">
<dt id="numba.cuda.grid">
<code class="descclassname">numba.cuda.</code><code class="descname">grid</code><span class="sig-paren">(</span><em>ndim</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.grid" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the absolute position of the current thread in the entire
grid of blocks.  <em>ndim</em> should correspond to the number of dimensions
declared when instantiating the kernel.  If <em>ndim</em> is 1, a single integer
is returned.  If <em>ndim</em> is 2 or 3, a tuple of the given number of
integers is returned.</p>
<p>Computation of the first integer is as follows:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">cuda</span><span class="o">.</span><span class="n">threadIdx</span><span class="o">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">cuda</span><span class="o">.</span><span class="n">blockIdx</span><span class="o">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">cuda</span><span class="o">.</span><span class="n">blockDim</span><span class="o">.</span><span class="n">x</span>
</pre></div>
</div>
<p>and is similar for the other two indices, but using the <code class="docutils literal"><span class="pre">y</span></code> and <code class="docutils literal"><span class="pre">z</span></code>
attributes.</p>
</dd></dl>

<dl class="function">
<dt id="numba.cuda.gridsize">
<code class="descclassname">numba.cuda.</code><code class="descname">gridsize</code><span class="sig-paren">(</span><em>ndim</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.gridsize" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the absolute size (or shape) in threads of the entire grid of
blocks. <em>ndim</em> should correspond to the number of dimensions declared when
instantiating the kernel.</p>
<p>Computation of the first integer is as follows:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">cuda</span><span class="o">.</span><span class="n">blockDim</span><span class="o">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">cuda</span><span class="o">.</span><span class="n">gridDim</span><span class="o">.</span><span class="n">x</span>
</pre></div>
</div>
<p>and is similar for the other two indices, but using the <code class="docutils literal"><span class="pre">y</span></code> and <code class="docutils literal"><span class="pre">z</span></code>
attributes.</p>
</dd></dl>

</div>
<div class="section" id="memory-management">
<h3>4.2.2.2. Memory Management<a class="headerlink" href="#memory-management" title="Permalink to this headline">¶</a></h3>
<dl class="function">
<dt id="numba.cuda.shared.array">
<code class="descclassname">numba.cuda.shared.</code><code class="descname">array</code><span class="sig-paren">(</span><em>shape</em>, <em>dtype</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.shared.array" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates an array in the local memory space of the CUDA kernel with
the given <code class="docutils literal"><span class="pre">shape</span></code> and <code class="docutils literal"><span class="pre">dtype</span></code>.</p>
<p>Returns an array with its content uninitialized.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">All threads in the same thread block sees the same array.</p>
</div>
</dd></dl>

<dl class="function">
<dt id="numba.cuda.local.array">
<code class="descclassname">numba.cuda.local.</code><code class="descname">array</code><span class="sig-paren">(</span><em>shape</em>, <em>dtype</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.local.array" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates an array in the local memory space of the CUDA kernel with the
given <code class="docutils literal"><span class="pre">shape</span></code> and <code class="docutils literal"><span class="pre">dtype</span></code>.</p>
<p>Returns an array with its content uninitialized.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Each thread sees a unique array.</p>
</div>
</dd></dl>

<dl class="function">
<dt id="numba.cuda.const.array_like">
<code class="descclassname">numba.cuda.const.</code><code class="descname">array_like</code><span class="sig-paren">(</span><em>ary</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.const.array_like" title="Permalink to this definition">¶</a></dt>
<dd><p>Copies the <code class="docutils literal"><span class="pre">ary</span></code> into constant memory space on the CUDA kernel at compile
time.</p>
<p>Returns an array like the <code class="docutils literal"><span class="pre">ary</span></code> argument.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">All threads and blocks see the same array.</p>
</div>
</dd></dl>

</div>
<div class="section" id="synchronization-and-atomic-operations">
<h3>4.2.2.3. Synchronization and Atomic Operations<a class="headerlink" href="#synchronization-and-atomic-operations" title="Permalink to this headline">¶</a></h3>
<dl class="function">
<dt id="numba.cuda.atomic.add">
<code class="descclassname">numba.cuda.atomic.</code><code class="descname">add</code><span class="sig-paren">(</span><em>array</em>, <em>idx</em>, <em>value</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.atomic.add" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform <code class="docutils literal"><span class="pre">array[idx]</span> <span class="pre">+=</span> <span class="pre">value</span></code>. Support int32, int64, float32 and
float64 only. The <code class="docutils literal"><span class="pre">idx</span></code> argument can be an integer or a tuple of integer
indices for indexing into multiple dimensional arrays. The number of element
in <code class="docutils literal"><span class="pre">idx</span></code> must match the number of dimension of <code class="docutils literal"><span class="pre">array</span></code>.</p>
<p>Returns the value of <code class="docutils literal"><span class="pre">array[idx]</span></code> before the storing the new value.
Behaves like an atomic load.</p>
</dd></dl>

<dl class="function">
<dt id="numba.cuda.atomic.max">
<code class="descclassname">numba.cuda.atomic.</code><code class="descname">max</code><span class="sig-paren">(</span><em>array</em>, <em>idx</em>, <em>value</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.atomic.max" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform <code class="docutils literal"><span class="pre">array[idx]</span> <span class="pre">=</span> <span class="pre">max(array[idx],</span> <span class="pre">value)</span></code>. Support int32, int64,
float32 and float64 only. The <code class="docutils literal"><span class="pre">idx</span></code> argument can be an integer or a
tuple of integer indices for indexing into multiple dimensional arrays.
The number of element in <code class="docutils literal"><span class="pre">idx</span></code> must match the number of dimension of
<code class="docutils literal"><span class="pre">array</span></code>.</p>
<p>Returns the value of <code class="docutils literal"><span class="pre">array[idx]</span></code> before the storing the new value.
Behaves like an atomic load.</p>
</dd></dl>

<dl class="function">
<dt id="numba.cuda.syncthreads">
<code class="descclassname">numba.cuda.</code><code class="descname">syncthreads</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.syncthreads" title="Permalink to this definition">¶</a></dt>
<dd><p>Synchronize all threads in the same thread block.  This function implements
the same pattern as barriers in traditional multi-threaded programming: this
function waits until all threads in the block call it, at which point it
returns control to all its callers.</p>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p class="last">Must be called by every thread in the thread-block. Falling to
do so may result in undefined behavior.</p>
</div>
</dd></dl>

</div>
<div class="section" id="memory-fences">
<h3>4.2.2.4. Memory Fences<a class="headerlink" href="#memory-fences" title="Permalink to this headline">¶</a></h3>
<p>The memory fences are used to guarantee the effect of memory operations
are visible by other threads within the same thread-block, the same GPU device,
and the same system (across GPUs on global memory). Memory loads and stores
are guaranteed to not move across the memory fences by optimization passes.</p>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p class="last">The memory fences are considered to be advanced API and most
usercases should use the thread barrier (e.g. <code class="docutils literal"><span class="pre">syncthreads()</span></code>).</p>
</div>
<dl class="function">
<dt id="numba.cuda.threadfence">
<code class="descclassname">numba.cuda.</code><code class="descname">threadfence</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.threadfence" title="Permalink to this definition">¶</a></dt>
<dd><p>A memory fence at device level (within the GPU).</p>
</dd></dl>

<dl class="function">
<dt id="numba.cuda.threadfence_block">
<code class="descclassname">numba.cuda.</code><code class="descname">threadfence_block</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.threadfence_block" title="Permalink to this definition">¶</a></dt>
<dd><p>A memory fence at thread block level.</p>
</dd></dl>

<dl class="function">
<dt id="numba.cuda.threadfence_system">
<code class="descclassname">numba.cuda.</code><code class="descname">threadfence_system</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.threadfence_system" title="Permalink to this definition">¶</a></dt>
<dd><p>A memory fence at system level (across GPUs)</p>
</dd></dl>

</div>
</div>
</div>


                </div>
              </div>
            </div>
          </div>
        </div>
        
        
      </div><!-- /row -->

      <!-- row -->
      <div class="row-fluid">
<div class="related navbar ">
  <div class="navbar-inner">
    <ul class="nav pull-right">
      
        <li><a href="../genindex.html" title="General Index" >index</a></li>
        <li><a href="memory.html" title="4.3. Memory Management" >next</a></li>
        <li><a href="host.html" title="4.1. CUDA Host API" >previous</a></li>
        <li><a href="../index.html">Numba 0.22.1+318.g54f93d9-py2.7-linux-x86_64.egg documentation</a></li>
        <li><a href="index.html" >4. CUDA Python Reference</a></li> 
      
    </ul>
  </div>
</div>
      </div><!-- /row -->

      <!-- footer -->
      <footer>
          &copy; Copyright 2012-2015, Continuum Analytics.
        Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.3.1.
      </footer>
      <!-- /footer -->

    </div>
    <!-- /container -->

  </body>
</html>