<!DOCTYPE html>




<html lang="en">
  <head>
    <meta charset="utf-8" />
    
    <title>4.2. CUDA Kernel API &mdash; Numba 0.20.0+189.gaebd68d-py2.7-linux-x86_64.egg documentation</title>

    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">
    <meta name="author" content="">

    
<link rel="stylesheet" href="../_static/css/basicstrap-base.css" type="text/css" />
<link rel="stylesheet" href="../_static/css/bootstrap.min.css" type="text/css" />
<link rel="stylesheet" href="../_static/css/font-awesome.min.css">
<!--[if IE 7]>
<link rel="stylesheet" href="../_static/css/font-awesome-ie7.min.css">
<![endif]-->
<style type="text/css">
  body {
    padding-top: 60px;
    padding-bottom: 40px;
  }
}
</style>
<link rel="stylesheet" href="../_static/basicstrap.css" type="text/css" />
<link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
<link rel="stylesheet" href="../_static/css/bootstrap-responsive.min.css" type="text/css" />
    
<script type="text/javascript">
  var DOCUMENTATION_OPTIONS = {
            URL_ROOT:    '../',
            VERSION:     '0.20.0+189.gaebd68d-py2.7-linux-x86_64.egg',
            COLLAPSE_INDEX: false,
            FILE_SUFFIX: '.html',
            HAS_SOURCE:  true
  };
</script>
<script type="text/javascript" src="../_static/js/jquery.min.js"></script>
<script type="text/javascript" src="../_static/underscore.js"></script>
<script type="text/javascript" src="../_static/doctools.js"></script>
<script type="text/javascript" src="../_static/js/bootstrap.min.js"></script>
<script type="text/javascript">
  $(document).ready(function(){
    $('.show-sidebar').click(function(e) {
       e.preventDefault();
       if ($(".show-sidebar").html() == "Open Table Of Contents") {
          $('.for-mobile').removeClass('hidden-phone');
          $(".show-sidebar").html("Close Table Of Contents");
       } else {
          $(".show-sidebar").html("Open Table Of Contents");
       }
    });
  });
</script>
    <link rel="top" title="Numba 0.20.0+189.gaebd68d-py2.7-linux-x86_64.egg documentation" href="../index.html" />
    <link rel="up" title="4. CUDA Python Reference" href="index.html" />
    <link rel="next" title="4.3. Memory Management" href="memory.html" />
    <link rel="prev" title="4.1. CUDA Host API" href="host.html" /> 
  </head>
  <body>
    <div class="navbar navbar-fixed-top ">
      <div class="navbar-inner">
        <div class="container-fluid">
          <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </a>
          <a class="brand" href="../index.html">Numba 0.20.0+189.gaebd68d-py2.7-linux-x86_64.egg documentation</a>
          <div class="nav-collapse collapse">
            <ul class="nav pull-right">
              
                <li>
                <a href="../genindex.html" title="General Index" accesskey="I">index</a>
                </li>
                <li>
                <a href="memory.html" title="4.3. Memory Management" accesskey="N">next</a>
                </li>
                <li>
                <a href="host.html" title="4.1. CUDA Host API" accesskey="P">previous</a>
                </li>
                <li>
                <a href="index.html" accesskey="U">4. CUDA Python Reference</a>
                </li>
              
            </ul>
          </div>
        </div>
      </div>
    </div>
    

    <!-- container -->
    <div class="container-fluid">


      
      <div class="row-fluid hidden-desktop hidden-tablet">
      
<div class="span3 ">
  <a class="visible-phone btn btn-small show-sidebar" data-toggle="collapse" data-target=".for-mobile">Open Table Of Contents</a>
  <div class="for-mobile sidebar hidden-phone">
  <h3><a href="../index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">4.2. CUDA Kernel API</a><ul>
<li><a class="reference internal" href="#kernel-declaration">4.2.1. Kernel declaration</a></li>
<li><a class="reference internal" href="#intrinsic-attributes-and-functions">4.2.2. Intrinsic Attributes and Functions</a><ul>
<li><a class="reference internal" href="#thread-indexing">4.2.2.1. Thread Indexing</a></li>
<li><a class="reference internal" href="#memory-management">4.2.2.2. Memory Management</a></li>
<li><a class="reference internal" href="#synchronization-and-atomic-operations">4.2.2.3. Synchronization and Atomic Operations</a></li>
</ul>
</li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="host.html"
                        title="previous chapter">4.1. CUDA Host API</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="memory.html"
                        title="next chapter">4.3. Memory Management</a></p>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../_sources/cuda-reference/kernel.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox">
  <h3>Quick search</h3>
  <form class="search form-search" action="../search.html" method="get">
      <div class="input-append">
        <input type="text" class="search-query" name="q">
        <input type="submit" class="btn" value="Go" />
      </div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
  </div>
</div>
      </div>
      

      <!-- row -->
      <div class="row-fluid">
         
<div class="span3 visible-desktop visible-tablet">
  <div class=" sidebar hidden-phone">
  <h3><a href="../index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">4.2. CUDA Kernel API</a><ul>
<li><a class="reference internal" href="#kernel-declaration">4.2.1. Kernel declaration</a></li>
<li><a class="reference internal" href="#intrinsic-attributes-and-functions">4.2.2. Intrinsic Attributes and Functions</a><ul>
<li><a class="reference internal" href="#thread-indexing">4.2.2.1. Thread Indexing</a></li>
<li><a class="reference internal" href="#memory-management">4.2.2.2. Memory Management</a></li>
<li><a class="reference internal" href="#synchronization-and-atomic-operations">4.2.2.3. Synchronization and Atomic Operations</a></li>
</ul>
</li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="host.html"
                        title="previous chapter">4.1. CUDA Host API</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="memory.html"
                        title="next chapter">4.3. Memory Management</a></p>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../_sources/cuda-reference/kernel.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox">
  <h3>Quick search</h3>
  <form class="search form-search" action="../search.html" method="get">
      <div class="input-append">
        <input type="text" class="search-query" name="q">
        <input type="submit" class="btn" value="Go" />
      </div>
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
  </div>
</div> 
        

        <div class="span9">
          <div class="document">
            <div class="documentwrapper">
              <div class="bodywrapper">
                <div class="body">
                  
  <div class="section" id="cuda-kernel-api">
<h1>4.2. CUDA Kernel API<a class="headerlink" href="#cuda-kernel-api" title="Permalink to this headline">¶</a></h1>
<div class="section" id="kernel-declaration">
<h2>4.2.1. Kernel declaration<a class="headerlink" href="#kernel-declaration" title="Permalink to this headline">¶</a></h2>
<p>The <code class="docutils literal"><span class="pre">&#64;cuda.jit</span></code> decorator is used to create a CUDA kernel:</p>
<dl class="function">
<dt id="numba.cuda.jit">
<code class="descclassname">numba.cuda.</code><code class="descname">jit</code><span class="sig-paren">(</span><em>func_or_sig=None</em>, <em>argtypes=None</em>, <em>device=False</em>, <em>inline=False</em>, <em>bind=True</em>, <em>link=[]</em>, <em>debug=False</em>, <em>**kws</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.jit" title="Permalink to this definition">¶</a></dt>
<dd><p>JIT compile a python function conforming to the CUDA Python specification.
If a signature is supplied, then a function is returned that takes a
function to compile. If</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>func_or_sig</strong> (<em>function or numba.typing.Signature</em>) &#8211; <p>A function to JIT compile, or a signature of a function
to compile. If a function is supplied, then an <code class="xref py py-class docutils literal"><span class="pre">AutoJitCUDAKernel</span></code>
is returned. If a signature is supplied, then a function which takes a
function to compile and returns an <code class="xref py py-class docutils literal"><span class="pre">AutoJitCUDAKernel</span></code> is
returned.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">A kernel cannot have any return value.</p>
</div>
</li>
<li><strong>device</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.4)"><em>bool</em></a>) &#8211; Indicates whether this is a device function.</li>
<li><strong>bind</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.4)"><em>bool</em></a>) &#8211; Force binding to CUDA context immediately</li>
<li><strong>link</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.4)"><em>list</em></a>) &#8211; A list of files containing PTX source to link with the function</li>
<li><strong>debug</strong> &#8211; If True, check for exceptions thrown when executing the
kernel. Since this degrades performance, this should only be used for
debugging purposes.</li>
<li><strong>fastmath</strong> &#8211; If true, enables flush-to-zero and fused-multiply-add,
disables precise division and square root. This parameter has no effect
on device function, whose fastmath setting depends on the kernel function
from which they are called.</li>
</ul>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="class">
<dt id="numba.cuda.compiler.AutoJitCUDAKernel">
<em class="property">class </em><code class="descclassname">numba.cuda.compiler.</code><code class="descname">AutoJitCUDAKernel</code><span class="sig-paren">(</span><em>func</em>, <em>bind</em>, <em>targetoptions</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.compiler.AutoJitCUDAKernel" title="Permalink to this definition">¶</a></dt>
<dd><p>CUDA Kernel object. When called, the kernel object will specialize itself
for the given arguments (if no suitable specialized version already exists)
and launch on the device associated with the current context.</p>
<p>Kernel objects are not to be constructed by the user, but instead are
created using the <a class="reference internal" href="#numba.cuda.jit" title="numba.cuda.jit"><code class="xref py py-func docutils literal"><span class="pre">numba.cuda.jit()</span></code></a> decorator.</p>
<dl class="method">
<dt id="numba.cuda.compiler.AutoJitCUDAKernel.inspect_asm">
<code class="descname">inspect_asm</code><span class="sig-paren">(</span><em>signature=None</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.compiler.AutoJitCUDAKernel.inspect_asm" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the generated assembly code for all signatures encountered thus
far, or the LLVM IR for a specific signature if given.</p>
</dd></dl>

<dl class="method">
<dt id="numba.cuda.compiler.AutoJitCUDAKernel.inspect_llvm">
<code class="descname">inspect_llvm</code><span class="sig-paren">(</span><em>signature=None</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.compiler.AutoJitCUDAKernel.inspect_llvm" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the LLVM IR for all signatures encountered thus far, or the LLVM
IR for a specific signature if given.</p>
</dd></dl>

<dl class="method">
<dt id="numba.cuda.compiler.AutoJitCUDAKernel.inspect_types">
<code class="descname">inspect_types</code><span class="sig-paren">(</span><em>file=None</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.compiler.AutoJitCUDAKernel.inspect_types" title="Permalink to this definition">¶</a></dt>
<dd><p>Produce a dump of the Python source of this function annotated with the
corresponding Numba IR and type information. The dump is written to
<em>file</em>, or <em>sys.stdout</em> if <em>file</em> is <em>None</em>.</p>
</dd></dl>

<dl class="method">
<dt id="numba.cuda.compiler.AutoJitCUDAKernel.specialize">
<code class="descname">specialize</code><span class="sig-paren">(</span><em>*args</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.compiler.AutoJitCUDAKernel.specialize" title="Permalink to this definition">¶</a></dt>
<dd><p>Compile and bind to the current context a version of this kernel
specialized for the given <em>args</em>.</p>
</dd></dl>

</dd></dl>

<p>Individual specialized kernels are instances of
<a class="reference internal" href="#numba.cuda.compiler.CUDAKernel" title="numba.cuda.compiler.CUDAKernel"><code class="xref py py-class docutils literal"><span class="pre">numba.cuda.compiler.CUDAKernel</span></code></a>:</p>
<dl class="class">
<dt id="numba.cuda.compiler.CUDAKernel">
<em class="property">class </em><code class="descclassname">numba.cuda.compiler.</code><code class="descname">CUDAKernel</code><span class="sig-paren">(</span><em>llvm_module</em>, <em>name</em>, <em>pretty_name</em>, <em>argtypes</em>, <em>call_helper</em>, <em>link=()</em>, <em>debug=False</em>, <em>fastmath=False</em>, <em>type_annotation=None</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.compiler.CUDAKernel" title="Permalink to this definition">¶</a></dt>
<dd><p>CUDA Kernel specialized for a given set of argument types. When called, this
object will validate that the argument types match those for which it is
specialized, and then launch the kernel on the device.</p>
<dl class="method">
<dt id="numba.cuda.compiler.CUDAKernel.bind">
<code class="descname">bind</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.compiler.CUDAKernel.bind" title="Permalink to this definition">¶</a></dt>
<dd><p>Force binding to current CUDA context</p>
</dd></dl>

<dl class="attribute">
<dt id="numba.cuda.compiler.CUDAKernel.device">
<code class="descname">device</code><a class="headerlink" href="#numba.cuda.compiler.CUDAKernel.device" title="Permalink to this definition">¶</a></dt>
<dd><p>Get current active context</p>
</dd></dl>

<dl class="method">
<dt id="numba.cuda.compiler.CUDAKernel.inspect_asm">
<code class="descname">inspect_asm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.compiler.CUDAKernel.inspect_asm" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the PTX code for this kernel.</p>
</dd></dl>

<dl class="method">
<dt id="numba.cuda.compiler.CUDAKernel.inspect_llvm">
<code class="descname">inspect_llvm</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.compiler.CUDAKernel.inspect_llvm" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the LLVM IR for this kernel.</p>
</dd></dl>

<dl class="method">
<dt id="numba.cuda.compiler.CUDAKernel.inspect_types">
<code class="descname">inspect_types</code><span class="sig-paren">(</span><em>file=None</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.compiler.CUDAKernel.inspect_types" title="Permalink to this definition">¶</a></dt>
<dd><p>Produce a dump of the Python source of this function annotated with the
corresponding Numba IR and type information. The dump is written to
<em>file</em>, or <em>sys.stdout</em> if <em>file</em> is <em>None</em>.</p>
</dd></dl>

<dl class="attribute">
<dt id="numba.cuda.compiler.CUDAKernel.ptx">
<code class="descname">ptx</code><a class="headerlink" href="#numba.cuda.compiler.CUDAKernel.ptx" title="Permalink to this definition">¶</a></dt>
<dd><p>PTX code for this kernel.</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="intrinsic-attributes-and-functions">
<h2>4.2.2. Intrinsic Attributes and Functions<a class="headerlink" href="#intrinsic-attributes-and-functions" title="Permalink to this headline">¶</a></h2>
<p>The remainder of the attributes and functions in this section may only be called
from within a CUDA Kernel.</p>
<div class="section" id="thread-indexing">
<h3>4.2.2.1. Thread Indexing<a class="headerlink" href="#thread-indexing" title="Permalink to this headline">¶</a></h3>
<dl class="function">
<dt id="numba.cuda.threadIdx">
<code class="descclassname">numba.cuda.</code><code class="descname">threadIdx</code><span class="sig-paren">(</span><em>cls</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.threadIdx" title="Permalink to this definition">¶</a></dt>
<dd><p>The thread indices in the current thread block, accessed through the
attributes <code class="docutils literal"><span class="pre">x</span></code>, <code class="docutils literal"><span class="pre">y</span></code>, and <code class="docutils literal"><span class="pre">z</span></code>. Each index is an integer spanning the
range from 0 inclusive to the corresponding value of the attribute in
<a class="reference internal" href="#numba.cuda.blockDim" title="numba.cuda.blockDim"><code class="xref py py-attr docutils literal"><span class="pre">numba.cuda.blockDim</span></code></a> exclusive.</p>
</dd></dl>

<dl class="function">
<dt id="numba.cuda.blockIdx">
<code class="descclassname">numba.cuda.</code><code class="descname">blockIdx</code><span class="sig-paren">(</span><em>cls</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.blockIdx" title="Permalink to this definition">¶</a></dt>
<dd><p>The block indices in the grid of thread blocks, accessed through the
attributes <code class="docutils literal"><span class="pre">x</span></code>, <code class="docutils literal"><span class="pre">y</span></code>, and <code class="docutils literal"><span class="pre">z</span></code>. Each index is an integer spanning the
range from 0 inclusive to the corresponding value of the attribute in
<a class="reference internal" href="#numba.cuda.gridDim" title="numba.cuda.gridDim"><code class="xref py py-attr docutils literal"><span class="pre">numba.cuda.gridDim</span></code></a> exclusive.</p>
</dd></dl>

<dl class="function">
<dt id="numba.cuda.blockDim">
<code class="descclassname">numba.cuda.</code><code class="descname">blockDim</code><span class="sig-paren">(</span><em>cls</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.blockDim" title="Permalink to this definition">¶</a></dt>
<dd><p>The shape of a block of threads, as declared when instantiating the
kernel.  This value is the same for all threads in a given kernel, even
if they belong to different blocks (i.e. each block is &#8220;full&#8221;).</p>
</dd></dl>

<dl class="function">
<dt id="numba.cuda.gridDim">
<code class="descclassname">numba.cuda.</code><code class="descname">gridDim</code><span class="sig-paren">(</span><em>cls</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.gridDim" title="Permalink to this definition">¶</a></dt>
<dd><p>The shape of the grid of blocks, accressed through the attributes <code class="docutils literal"><span class="pre">x</span></code>,
<code class="docutils literal"><span class="pre">y</span></code>, and <code class="docutils literal"><span class="pre">z</span></code>.</p>
</dd></dl>

<dl class="function">
<dt id="numba.cuda.grid">
<code class="descclassname">numba.cuda.</code><code class="descname">grid</code><span class="sig-paren">(</span><em>ndim</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.grid" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the absolute position of the current thread in the entire
grid of blocks.  <em>ndim</em> should correspond to the number of dimensions
declared when instantiating the kernel.  If <em>ndim</em> is 1, a single integer
is returned.  If <em>ndim</em> is 2 or 3, a tuple of the given number of
integers is returned.</p>
<p>Computation of the first integer is as follows:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">cuda</span><span class="o">.</span><span class="n">threadIdx</span><span class="o">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">cuda</span><span class="o">.</span><span class="n">blockIdx</span><span class="o">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">cuda</span><span class="o">.</span><span class="n">blockDim</span><span class="o">.</span><span class="n">x</span>
</pre></div>
</div>
<p>and is similar for the other two indices, but using the <code class="docutils literal"><span class="pre">y</span></code> and <code class="docutils literal"><span class="pre">z</span></code>
attributes.</p>
</dd></dl>

<dl class="function">
<dt id="numba.cuda.gridsize">
<code class="descclassname">numba.cuda.</code><code class="descname">gridsize</code><span class="sig-paren">(</span><em>ndim</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.gridsize" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the absolute size (or shape) in threads of the entire grid of
blocks. <em>ndim</em> should correspond to the number of dimensions declared when
instantiating the kernel.</p>
<p>Computation of the first integer is as follows:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">cuda</span><span class="o">.</span><span class="n">blockDim</span><span class="o">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">cuda</span><span class="o">.</span><span class="n">gridDim</span><span class="o">.</span><span class="n">x</span>
</pre></div>
</div>
<p>and is similar for the other two indices, but using the <code class="docutils literal"><span class="pre">y</span></code> and <code class="docutils literal"><span class="pre">z</span></code>
attributes.</p>
</dd></dl>

</div>
<div class="section" id="memory-management">
<h3>4.2.2.2. Memory Management<a class="headerlink" href="#memory-management" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="numba.cuda.shared">
<em class="property">class </em><code class="descclassname">numba.cuda.</code><code class="descname">shared</code><a class="headerlink" href="#numba.cuda.shared" title="Permalink to this definition">¶</a></dt>
<dd><p>Shared memory namespace.</p>
<dl class="attribute">
<dt id="numba.cuda.shared.array">
<code class="descname">array</code><em class="property"> = &lt;macro shared.array -&gt; &lt;function shared_array at 0x2b32852f2230&gt;&gt;</em><a class="headerlink" href="#numba.cuda.shared.array" title="Permalink to this definition">¶</a></dt>
<dd><p>Allocate a shared array of the given <em>shape</em> and <em>type</em>. <em>shape</em> is either
an integer or a tuple of integers representing the array&#8217;s dimensions.
<em>type</em> is a <a class="reference internal" href="../reference/types.html#numba-types"><span>Numba type</span></a> of the elements needing to be
stored in the array.</p>
<p>The returned array-like object can be read and written to like any normal
device array (e.g. through indexing).</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="numba.cuda.local">
<em class="property">class </em><code class="descclassname">numba.cuda.</code><code class="descname">local</code><a class="headerlink" href="#numba.cuda.local" title="Permalink to this definition">¶</a></dt>
<dd><p>Local memory namespace.</p>
<dl class="attribute">
<dt id="numba.cuda.local.array">
<code class="descname">array</code><em class="property"> = &lt;macro local.array -&gt; &lt;function local_array at 0x2b32852f22a8&gt;&gt;</em><a class="headerlink" href="#numba.cuda.local.array" title="Permalink to this definition">¶</a></dt>
<dd><p>Allocate a local array of the given <em>shape</em> and <em>type</em>. The array is private
to the current thread, and resides in global memory. An array-like object is
returned which can be read and written to like any standard array (e.g.
through indexing).</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="numba.cuda.const">
<em class="property">class </em><code class="descclassname">numba.cuda.</code><code class="descname">const</code><a class="headerlink" href="#numba.cuda.const" title="Permalink to this definition">¶</a></dt>
<dd><p>Constant memory namespace.</p>
<dl class="attribute">
<dt id="numba.cuda.const.array_like">
<code class="descname">array_like</code><em class="property"> = &lt;macro const.array_like -&gt; &lt;function const_array_like at 0x2b32852f2320&gt;&gt;</em><a class="headerlink" href="#numba.cuda.const.array_like" title="Permalink to this definition">¶</a></dt>
<dd><p>Create a const array from <em>ary</em>. The resulting const array will have the
same shape, type, and values as <em>ary</em>.</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="synchronization-and-atomic-operations">
<h3>4.2.2.3. Synchronization and Atomic Operations<a class="headerlink" href="#synchronization-and-atomic-operations" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="numba.cuda.atomic">
<em class="property">class </em><code class="descclassname">numba.cuda.</code><code class="descname">atomic</code><a class="headerlink" href="#numba.cuda.atomic" title="Permalink to this definition">¶</a></dt>
<dd><p>Namespace for atomic operations</p>
<dl class="class">
<dt id="numba.cuda.atomic.add">
<em class="property">class </em><code class="descname">add</code><span class="sig-paren">(</span><em>ary</em>, <em>idx</em>, <em>val</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.atomic.add" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform atomic ary[idx] += val. Supported on int32, float32, and
float64 operands only.</p>
</dd></dl>

<dl class="class">
<dt id="numba.cuda.atomic.max">
<em class="property">class </em><code class="descclassname">atomic.</code><code class="descname">max</code><span class="sig-paren">(</span><em>ary</em>, <em>idx</em>, <em>val</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.atomic.max" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform atomic ary[idx] = max(ary[idx], val). NaN is treated as a
missing value, so max(NaN, n) == max(n, NaN) == n. Note that this
differs from Python and Numpy behaviour, where max(a, b) is always
a when either a or b is a NaN.</p>
<p>Supported on float64 operands only.</p>
</dd></dl>

</dd></dl>

<dl class="function">
<dt id="numba.cuda.syncthreads">
<code class="descclassname">numba.cuda.</code><code class="descname">syncthreads</code><span class="sig-paren">(</span><em>cls</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.syncthreads" title="Permalink to this definition">¶</a></dt>
<dd><p>Synchronize all threads in the same thread block.  This function implements
the same pattern as barriers in traditional multi-threaded programming: this
function waits until all threads in the block call it, at which point it
returns control to all its callers.</p>
</dd></dl>

</div>
</div>
</div>


                </div>
              </div>
            </div>
          </div>
        </div>
        
        
      </div><!-- /row -->

      <!-- row -->
      <div class="row-fluid">
<div class="related navbar ">
  <div class="navbar-inner">
    <ul class="nav pull-right">
      
        <li><a href="../genindex.html" title="General Index" >index</a></li>
        <li><a href="memory.html" title="4.3. Memory Management" >next</a></li>
        <li><a href="host.html" title="4.1. CUDA Host API" >previous</a></li>
        <li><a href="../index.html">Numba 0.20.0+189.gaebd68d-py2.7-linux-x86_64.egg documentation</a></li>
        <li><a href="index.html" >4. CUDA Python Reference</a></li> 
      
    </ul>
  </div>
</div>
      </div><!-- /row -->

      <!-- footer -->
      <footer>
          &copy; Copyright 2012-2015, Continuum Analytics.
        Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.3.1.
      </footer>
      <!-- /footer -->

    </div>
    <!-- /container -->

  </body>
</html>