<!DOCTYPE html>


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>4.1. CUDA Host API &mdash; Numba 0.43.0.dev0+561.ga2ef2ea-py2.7-linux-x86_64.egg documentation</title>
    
    <link rel="stylesheet" href="../_static/bootstrap-sphinx.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/numba-docs.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '0.43.0.dev0+561.ga2ef2ea-py2.7-linux-x86_64.egg',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="../_static/js/jquery-1.11.0.min.js"></script>
    <script type="text/javascript" src="../_static/js/jquery-fix.js"></script>
    <script type="text/javascript" src="../_static/bootstrap-3.3.7/js/bootstrap.min.js"></script>
    <script type="text/javascript" src="../_static/bootstrap-sphinx.js"></script>
    <link rel="top" title="Numba 0.43.0.dev0+561.ga2ef2ea-py2.7-linux-x86_64.egg documentation" href="../index.html" />
    <link rel="up" title="4. CUDA Python Reference" href="index.html" />
    <link rel="next" title="4.2. CUDA Kernel API" href="kernel.html" />
    <link rel="prev" title="4. CUDA Python Reference" href="index.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">

  </head>
  <body role="document">

  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="../index.html"><span><img src="../_static/numba_blue_icon_rgb.png"></span>
          Numba</a>
        <span class="navbar-text navbar-version pull-left"><b>0.43</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="../index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../user/index.html">1. User Manual</a></li>
<li class="toctree-l1"><a class="reference internal" href="../reference/index.html">2. Reference Manual</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cuda/index.html">3. Numba for CUDA GPUs</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">4. CUDA Python Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../roc/index.html">5. Numba for AMD ROC GPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../extending/index.html">6. Extending Numba</a></li>
<li class="toctree-l1"><a class="reference internal" href="../developer/index.html">7. Developer Manual</a></li>
<li class="toctree-l1"><a class="reference internal" href="../proposals/index.html">8. Numba Enhancement Proposals</a></li>
<li class="toctree-l1"><a class="reference internal" href="../glossary.html">9. Glossary</a></li>
<li class="toctree-l1"><a class="reference internal" href="../release-notes.html">10. Release Notes</a></li>
</ul>
</ul>
</li>
              
                <li class="dropdown">
  <a role="button"
     id="dLabelLocalToc"
     data-toggle="dropdown"
     data-target="#"
     href="#">Page <b class="caret"></b></a>
  <ul class="dropdown-menu localtoc"
      role="menu"
      aria-labelledby="dLabelLocalToc"><ul>
<li><a class="reference internal" href="#">4.1. CUDA Host API</a><ul>
<li><a class="reference internal" href="#device-management">4.1.1. Device Management</a><ul>
<li><a class="reference internal" href="#device-detection-and-enquiry">4.1.1.1. Device detection and enquiry</a></li>
<li><a class="reference internal" href="#context-management">4.1.1.2. Context management</a></li>
<li><a class="reference internal" href="#id1">4.1.1.3. Device management</a></li>
</ul>
</li>
<li><a class="reference internal" href="#measurement">4.1.2. Measurement</a><ul>
<li><a class="reference internal" href="#profiling">4.1.2.1. Profiling</a></li>
<li><a class="reference internal" href="#events">4.1.2.2. Events</a></li>
</ul>
</li>
<li><a class="reference internal" href="#stream-management">4.1.3. Stream Management</a></li>
</ul>
</li>
</ul>
</ul>
</li>
              
            
            
              
                
  <li>
    <a href="index.html" title="Previous Chapter: 4. CUDA Python Reference"><span class="glyphicon glyphicon-chevron-left visible-sm"></span><span class="hidden-sm hidden-tablet">&laquo; 4. CUDA Python R...</span>
    </a>
  </li>
  <li>
    <a href="kernel.html" title="Next Chapter: 4.2. CUDA Kernel API"><span class="glyphicon glyphicon-chevron-right visible-sm"></span><span class="hidden-sm hidden-tablet">4.2. CUDA Kernel... &raquo;</span>
    </a>
  </li>
              
            
            
            
            
              <li class="hidden-sm">
<div id="sourcelink">
  <a href="../_sources/cuda-reference/host.txt"
     rel="nofollow">Source</a>
</div></li>
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="../search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
    <div class="col-md-12 content">
      
  <div class="section" id="cuda-host-api">
<h1>4.1. CUDA Host API<a class="headerlink" href="#cuda-host-api" title="Permalink to this headline">¶</a></h1>
<div class="section" id="device-management">
<h2>4.1.1. Device Management<a class="headerlink" href="#device-management" title="Permalink to this headline">¶</a></h2>
<div class="section" id="device-detection-and-enquiry">
<h3>4.1.1.1. Device detection and enquiry<a class="headerlink" href="#device-detection-and-enquiry" title="Permalink to this headline">¶</a></h3>
<p>The following functions are available for querying the available hardware:</p>
<dl class="function">
<dt id="numba.cuda.is_available">
<code class="descclassname">numba.cuda.</code><code class="descname">is_available</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.is_available" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a boolean to indicate the availability of a CUDA GPU.</p>
<p>This will initialize the driver if it hasn&#8217;t been initialized.</p>
</dd></dl>

<dl class="function">
<dt id="numba.cuda.detect">
<code class="descclassname">numba.cuda.</code><code class="descname">detect</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.detect" title="Permalink to this definition">¶</a></dt>
<dd><p>Detect supported CUDA hardware and print a summary of the detected hardware.</p>
<p>Returns a boolean indicating whether any supported devices were detected.</p>
</dd></dl>

</div>
<div class="section" id="context-management">
<h3>4.1.1.2. Context management<a class="headerlink" href="#context-management" title="Permalink to this headline">¶</a></h3>
<p>CUDA Python functions execute within a CUDA context. Each CUDA device in a
system has an associated CUDA context, and Numba presently allows only one context
per thread. For further details on CUDA Contexts, refer to the <a class="reference external" href="http://docs.nvidia.com/cuda/cuda-driver-api/group__CUDA__CTX.html">CUDA Driver API
Documentation on Context Management</a> and the
<a class="reference external" href="http://docs.nvidia.com/cuda/cuda-c-programming-guide/#context">CUDA C Programming Guide Context Documentation</a>. CUDA Contexts
are instances of the <a class="reference internal" href="#numba.cuda.cudadrv.driver.Context" title="numba.cuda.cudadrv.driver.Context"><code class="xref py py-class docutils literal"><span class="pre">Context</span></code></a> class:</p>
<dl class="class">
<dt id="numba.cuda.cudadrv.driver.Context">
<em class="property">class </em><code class="descclassname">numba.cuda.cudadrv.driver.</code><code class="descname">Context</code><span class="sig-paren">(</span><em>device</em>, <em>handle</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.cudadrv.driver.Context" title="Permalink to this definition">¶</a></dt>
<dd><p>This object wraps a CUDA Context resource.</p>
<p>Contexts should not be constructed directly by user code.</p>
<dl class="method">
<dt id="numba.cuda.cudadrv.driver.Context.get_memory_info">
<code class="descname">get_memory_info</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.cudadrv.driver.Context.get_memory_info" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns (free, total) memory in bytes in the context.</p>
</dd></dl>

<dl class="method">
<dt id="numba.cuda.cudadrv.driver.Context.pop">
<code class="descname">pop</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.cudadrv.driver.Context.pop" title="Permalink to this definition">¶</a></dt>
<dd><p>Pops this context off the current CPU thread. Note that this context must
be at the top of the context stack, otherwise an error will occur.</p>
</dd></dl>

<dl class="method">
<dt id="numba.cuda.cudadrv.driver.Context.push">
<code class="descname">push</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.cudadrv.driver.Context.push" title="Permalink to this definition">¶</a></dt>
<dd><p>Pushes this context on the current CPU Thread.</p>
</dd></dl>

<dl class="method">
<dt id="numba.cuda.cudadrv.driver.Context.reset">
<code class="descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.cudadrv.driver.Context.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Clean up all owned resources in this context.</p>
</dd></dl>

</dd></dl>

<p>The following functions can be used to get or select the context:</p>
<dl class="function">
<dt id="numba.cuda.current_context">
<code class="descclassname">numba.cuda.</code><code class="descname">current_context</code><span class="sig-paren">(</span><em>devnum=0</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.current_context" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the current device or use a device by device number, and
return the CUDA context.</p>
</dd></dl>

<dl class="function">
<dt id="numba.cuda.require_context">
<code class="descclassname">numba.cuda.</code><code class="descname">require_context</code><span class="sig-paren">(</span><em>fn</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.require_context" title="Permalink to this definition">¶</a></dt>
<dd><p>A decorator that ensures a CUDA context is available when <em>fn</em> is executed.</p>
<p>Decorating <em>fn</em> is equivalent to writing:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">get_context</span><span class="p">()</span>
<span class="n">fn</span><span class="p">()</span>
</pre></div>
</div>
<p>at each call site.</p>
</dd></dl>

<p>The following functions affect the current context:</p>
<dl class="function">
<dt id="numba.cuda.synchronize">
<code class="descclassname">numba.cuda.</code><code class="descname">synchronize</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.synchronize" title="Permalink to this definition">¶</a></dt>
<dd><p>Synchronize the current context.</p>
</dd></dl>

<dl class="function">
<dt id="numba.cuda.close">
<code class="descclassname">numba.cuda.</code><code class="descname">close</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.close" title="Permalink to this definition">¶</a></dt>
<dd><p>Explicitly clears all contexts in the current thread, and destroys all
contexts if the current thread is the main thread.</p>
</dd></dl>

</div>
<div class="section" id="id1">
<h3>4.1.1.3. Device management<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h3>
<p>Numba maintains a list of supported CUDA-capable devices:</p>
<dl class="attribute">
<dt id="numba.cuda.gpus">
<code class="descclassname">numba.cuda.</code><code class="descname">gpus</code><a class="headerlink" href="#numba.cuda.gpus" title="Permalink to this definition">¶</a></dt>
<dd><p>An indexable list of supported CUDA devices. This list is indexed by integer
device ID.</p>
</dd></dl>

<p>Alternatively, the current device can be obtained:</p>
<dl class="function">
<dt id="numba.cuda.gpus.current">
<code class="descclassname">numba.cuda.gpus.</code><code class="descname">current</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.gpus.current" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the currently-selected device.</p>
</dd></dl>

<p>Getting a device through <a class="reference internal" href="#numba.cuda.gpus" title="numba.cuda.gpus"><code class="xref py py-attr docutils literal"><span class="pre">numba.cuda.gpus</span></code></a> always provides an instance of
<a class="reference internal" href="#numba.cuda.cudadrv.devices._DeviceContextManager" title="numba.cuda.cudadrv.devices._DeviceContextManager"><code class="xref py py-class docutils literal"><span class="pre">numba.cuda.cudadrv.devices._DeviceContextManager</span></code></a>, which acts as a
context manager for the selected device:</p>
<dl class="class">
<dt id="numba.cuda.cudadrv.devices._DeviceContextManager">
<em class="property">class </em><code class="descclassname">numba.cuda.cudadrv.devices.</code><code class="descname">_DeviceContextManager</code><span class="sig-paren">(</span><em>device</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.cudadrv.devices._DeviceContextManager" title="Permalink to this definition">¶</a></dt>
<dd><p>Provides a context manager for executing in the context of the chosen
device. The normal use of instances of this type is from
<code class="docutils literal"><span class="pre">numba.cuda.gpus</span></code>. For example, to execute on device 2:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">with</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">gpus</span><span class="p">[</span><span class="mi">2</span><span class="p">]:</span>
    <span class="n">d_a</span> <span class="o">=</span> <span class="n">numba</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">to_device</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
</pre></div>
</div>
<p>to copy the array <em>a</em> onto device 2, referred to by <em>d_a</em>.</p>
</dd></dl>

<p>One may also select a context and device or get the current device using the
following three functions:</p>
<dl class="function">
<dt id="numba.cuda.select_device">
<code class="descclassname">numba.cuda.</code><code class="descname">select_device</code><span class="sig-paren">(</span><em>device_id</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.select_device" title="Permalink to this definition">¶</a></dt>
<dd><p>Make the context associated with device <em>device_id</em> the current context.</p>
<p>Returns a Device instance.</p>
<p>Raises exception on error.</p>
</dd></dl>

<dl class="function">
<dt id="numba.cuda.get_current_device">
<code class="descclassname">numba.cuda.</code><code class="descname">get_current_device</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.get_current_device" title="Permalink to this definition">¶</a></dt>
<dd><p>Get current device associated with the current thread</p>
</dd></dl>

<dl class="function">
<dt id="numba.cuda.list_devices">
<code class="descclassname">numba.cuda.</code><code class="descname">list_devices</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.list_devices" title="Permalink to this definition">¶</a></dt>
<dd><p>Return a list of all detected devices</p>
</dd></dl>

<p>The <a class="reference internal" href="#numba.cuda.cudadrv.driver.Device" title="numba.cuda.cudadrv.driver.Device"><code class="xref py py-class docutils literal"><span class="pre">numba.cuda.cudadrv.driver.Device</span></code></a> class can be used to enquire about
the functionality of the selected device:</p>
<dl class="class">
<dt id="numba.cuda.cudadrv.driver.Device">
<em class="property">class </em><code class="descclassname">numba.cuda.cudadrv.driver.</code><code class="descname">Device</code><a class="headerlink" href="#numba.cuda.cudadrv.driver.Device" title="Permalink to this definition">¶</a></dt>
<dd><p>The device associated with a particular context.</p>
<dl class="attribute">
<dt id="numba.cuda.cudadrv.driver.Device.compute_capability">
<code class="descname">compute_capability</code><a class="headerlink" href="#numba.cuda.cudadrv.driver.Device.compute_capability" title="Permalink to this definition">¶</a></dt>
<dd><p>A tuple, <em>(major, minor)</em> indicating the supported compute capability.</p>
</dd></dl>

<dl class="attribute">
<dt id="numba.cuda.cudadrv.driver.Device.id">
<code class="descname">id</code><a class="headerlink" href="#numba.cuda.cudadrv.driver.Device.id" title="Permalink to this definition">¶</a></dt>
<dd><p>The integer ID of the device.</p>
</dd></dl>

<dl class="attribute">
<dt id="numba.cuda.cudadrv.driver.Device.name">
<code class="descname">name</code><a class="headerlink" href="#numba.cuda.cudadrv.driver.Device.name" title="Permalink to this definition">¶</a></dt>
<dd><p>The name of the device (e.g. &#8220;GeForce GTX 970&#8221;)</p>
</dd></dl>

<dl class="method">
<dt id="numba.cuda.cudadrv.driver.Device.reset">
<code class="descname">reset</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.cudadrv.driver.Device.reset" title="Permalink to this definition">¶</a></dt>
<dd><p>Delete the context for the device. This will destroy all memory
allocations, events, and streams created within the context.</p>
</dd></dl>

</dd></dl>

</div>
</div>
<div class="section" id="measurement">
<h2>4.1.2. Measurement<a class="headerlink" href="#measurement" title="Permalink to this headline">¶</a></h2>
<div class="section" id="profiling">
<span id="cuda-profiling"></span><h3>4.1.2.1. Profiling<a class="headerlink" href="#profiling" title="Permalink to this headline">¶</a></h3>
<p>The NVidia Visual Profiler can be used directly on executing CUDA Python code -
it is not a requirement to insert calls to these functions into user code.
However, these functions can be used to allow profiling to be performed
selectively on specific portions of the code. For further information on
profiling, see the <a class="reference external" href="docs.nvidia.com/cuda/profiler-users-guide/">NVidia Profiler User&#8217;s Guide</a>.</p>
<dl class="function">
<dt id="numba.cuda.profile_start">
<code class="descclassname">numba.cuda.</code><code class="descname">profile_start</code><span class="sig-paren">(</span><em>*args</em>, <em>**kws</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.profile_start" title="Permalink to this definition">¶</a></dt>
<dd><p>Enable profile collection in the current context.</p>
</dd></dl>

<dl class="function">
<dt id="numba.cuda.profile_stop">
<code class="descclassname">numba.cuda.</code><code class="descname">profile_stop</code><span class="sig-paren">(</span><em>*args</em>, <em>**kws</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.profile_stop" title="Permalink to this definition">¶</a></dt>
<dd><p>Disable profile collection in the current context.</p>
</dd></dl>

<dl class="function">
<dt id="numba.cuda.profiling">
<code class="descclassname">numba.cuda.</code><code class="descname">profiling</code><span class="sig-paren">(</span><em>*args</em>, <em>**kws</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.profiling" title="Permalink to this definition">¶</a></dt>
<dd><p>Context manager that enables profiling on entry and disables profiling on
exit.</p>
</dd></dl>

</div>
<div class="section" id="events">
<h3>4.1.2.2. Events<a class="headerlink" href="#events" title="Permalink to this headline">¶</a></h3>
<p>Events can be used to monitor the progress of execution and to record the
timestamps of specific points being reached. Event creation returns immediately,
and the created event can be queried to determine if it has been reached. For
further information, see the <a class="reference external" href="http://docs.nvidia.com/cuda/cuda-c-programming-guide/#events">CUDA C Programming Guide Events section</a>.</p>
<p>The following functions are used for creating and measuring the time between
events:</p>
<dl class="function">
<dt id="numba.cuda.event">
<code class="descclassname">numba.cuda.</code><code class="descname">event</code><span class="sig-paren">(</span><em>timing=True</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.event" title="Permalink to this definition">¶</a></dt>
<dd><p>Create a CUDA event. Timing data is only recorded by the event if it is
created with <code class="docutils literal"><span class="pre">timing=True</span></code>.</p>
</dd></dl>

<dl class="function">
<dt id="numba.cuda.event_elapsed_time">
<code class="descclassname">numba.cuda.</code><code class="descname">event_elapsed_time</code><span class="sig-paren">(</span><em>evtstart</em>, <em>evtend</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.event_elapsed_time" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute the elapsed time between two events in milliseconds.</p>
</dd></dl>

<p>Events are instances of the <a class="reference internal" href="#numba.cuda.cudadrv.driver.Event" title="numba.cuda.cudadrv.driver.Event"><code class="xref py py-class docutils literal"><span class="pre">numba.cuda.cudadrv.driver.Event</span></code></a> class:</p>
<dl class="class">
<dt id="numba.cuda.cudadrv.driver.Event">
<em class="property">class </em><code class="descclassname">numba.cuda.cudadrv.driver.</code><code class="descname">Event</code><span class="sig-paren">(</span><em>context</em>, <em>handle</em>, <em>finalizer=None</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.cudadrv.driver.Event" title="Permalink to this definition">¶</a></dt>
<dd><dl class="method">
<dt id="numba.cuda.cudadrv.driver.Event.query">
<code class="descname">query</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.cudadrv.driver.Event.query" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns True if all work before the most recent record has completed;
otherwise, returns False.</p>
</dd></dl>

<dl class="method">
<dt id="numba.cuda.cudadrv.driver.Event.record">
<code class="descname">record</code><span class="sig-paren">(</span><em>stream=0</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.cudadrv.driver.Event.record" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the record point of the event to the current point in the given
stream.</p>
<p>The event will be considered to have occurred when all work that was
queued in the stream at the time of the call to <code class="docutils literal"><span class="pre">record()</span></code> has been
completed.</p>
</dd></dl>

<dl class="method">
<dt id="numba.cuda.cudadrv.driver.Event.synchronize">
<code class="descname">synchronize</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.cudadrv.driver.Event.synchronize" title="Permalink to this definition">¶</a></dt>
<dd><p>Synchronize the host thread for the completion of the event.</p>
</dd></dl>

<dl class="method">
<dt id="numba.cuda.cudadrv.driver.Event.wait">
<code class="descname">wait</code><span class="sig-paren">(</span><em>stream=0</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.cudadrv.driver.Event.wait" title="Permalink to this definition">¶</a></dt>
<dd><p>All future works submitted to stream will wait util the event completes.</p>
</dd></dl>

</dd></dl>

</div>
</div>
<div class="section" id="stream-management">
<h2>4.1.3. Stream Management<a class="headerlink" href="#stream-management" title="Permalink to this headline">¶</a></h2>
<p>Streams allow concurrency of execution on a single device within a given
context. Queued work items in the same stream execute sequentially, but work
items in different streams may execute concurrently. Most operations involving a
CUDA device can be performed asynchronously using streams, including data
transfers and kernel execution. For further details on streams, see the <a class="reference external" href="http://docs.nvidia.com/cuda/cuda-c-programming-guide/#streams">CUDA C
Programming Guide Streams section</a>.</p>
<p>To create a stream:</p>
<dl class="function">
<dt id="numba.cuda.stream">
<code class="descclassname">numba.cuda.</code><code class="descname">stream</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.stream" title="Permalink to this definition">¶</a></dt>
<dd><p>Create a CUDA stream that represents a command queue for the device.</p>
</dd></dl>

<p>Streams are instances of <a class="reference internal" href="#numba.cuda.cudadrv.driver.Stream" title="numba.cuda.cudadrv.driver.Stream"><code class="xref py py-class docutils literal"><span class="pre">numba.cuda.cudadrv.driver.Stream</span></code></a>:</p>
<dl class="class">
<dt id="numba.cuda.cudadrv.driver.Stream">
<em class="property">class </em><code class="descclassname">numba.cuda.cudadrv.driver.</code><code class="descname">Stream</code><span class="sig-paren">(</span><em>context</em>, <em>handle</em>, <em>finalizer</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.cudadrv.driver.Stream" title="Permalink to this definition">¶</a></dt>
<dd><dl class="method">
<dt id="numba.cuda.cudadrv.driver.Stream.auto_synchronize">
<code class="descname">auto_synchronize</code><span class="sig-paren">(</span><em>*args</em>, <em>**kwds</em><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.cudadrv.driver.Stream.auto_synchronize" title="Permalink to this definition">¶</a></dt>
<dd><p>A context manager that waits for all commands in this stream to execute
and commits any pending memory transfers upon exiting the context.</p>
</dd></dl>

<dl class="method">
<dt id="numba.cuda.cudadrv.driver.Stream.synchronize">
<code class="descname">synchronize</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#numba.cuda.cudadrv.driver.Stream.synchronize" title="Permalink to this definition">¶</a></dt>
<dd><p>Wait for all commands in this stream to execute. This will commit any
pending memory transfers.</p>
</dd></dl>

</dd></dl>

</div>
</div>


    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
    </p>
    <p>
        &copy; Copyright 2012, Anaconda, Inc..<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.3.1.<br/>
    </p>
  </div>
</footer>
  </body>
</html>